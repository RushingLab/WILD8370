[{"path":"http://rushinglab.github.io/WILD8370/articles/Lab01b_Mathematical_Notation.html","id":"analysis-flowchart","dir":"Articles","previous_headings":"","what":"Analysis Flowchart","title":"Lab1: Mathematical Notation","text":"One hardest part Bayesian analysis converting idea ecological system English math math English. Unlike lot maximum likelihood packages, get decide exact variable model defined, distributions think parameters come , assumptions making underlying system trying understand. process made confusing fact aren’t directly math ! can think process fun little flow chart:  Steps 1 -3 specific Bayesian analysis – need thing maximum likelihood analysis well. Also notice steps 4 5 simply Bayesian analysis class. need MCMC software R perform Bayesian analysis, just happens easiest way . key step help way practicing reading math equations translating English translating code.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab01b_Mathematical_Notation.html","id":"some-useful-notation","dir":"Articles","previous_headings":"","what":"Some Useful Notation","title":"Lab1: Mathematical Notation","text":"E(x)E(x) expected value something. instance, xx number frogs pond, E(x)E(x) expected number frogs pond. ϕ\\phi Phi, usually used indicate survival probability (can also used willy-nilly) Norm(μ,σ2)Norm( \\mu, \\sigma^2) normal distribution mean μ\\mu standard deviation σ\\sigma. Pois(λ)Pois(\\lambda) poisson distribution mean λ\\lambda. poisson accepts produces zero positive values Binom(N,p)Binom(N, p) binomial distribution size NN probability success pp. ∑j=1wKj\\sum^w_{j=1} K_j sum value KjK_j values jj 1 ww. instance, KjK_j represents number personalized mugs Dr. Rushing’s office year jj , sum year j=3j = 3 year 10 ∑j=310Kj\\sum^{10}_{j=3} K_j β0+ϵ∼Norm(0,σ2)\\beta_0 + \\epsilon \\sim Norm(0, \\sigma^2) shorthand way saying residuals equation normally distributed. assumption linear models can quicker write way rather line E(x)E(x) line residuals. β0+β1[q]\\beta_0 + \\beta_1[q] value β1\\beta_1 depends value integer qq. qq can take 3 values (1, 2, 3), know three possible values β1\\beta_1. commonly used categorical variables. logit(x)=β0logit(x) = \\beta_0 tells us xx probability scale (0 1) β0\\beta_0 logit scale (real numbers). R, knew β0\\beta_0 wanted get xx, type: plogis( β0\\beta_0 )","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab01b_Mathematical_Notation.html","id":"math-to-english","dir":"Articles","previous_headings":"","what":"Math to English","title":"Lab1: Mathematical Notation","text":"’ll often see people’s equations scientific papers want understand analysis.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab01b_Mathematical_Notation.html","id":"example-bears","dir":"Articles","previous_headings":"Math to English","what":"Example: Bears","title":"Lab1: Mathematical Notation","text":"want use data weight abundance black bears collected past decade determine bear health indices responds different environmental biological factors. ’re just going focus Process Model - , think system works, even can’t observe directly. following information available: Let’s say come following equation. mean English? E(weightit)=β0+β1*percentforestit+β2*sexiE(weight_{}) = \\beta_0 + \\beta_1*percentforest_{} + \\beta_2 * sex_i yit∼Normal(E(weightit),σ2)y_{} \\sim Normal(E(weight_{}), \\sigma^2) Answer: expected weight individual bear time tt function percent forest bear’s county sex bear. observed bear weight normal distribution centered around expected weight standard deviation σ\\sigma. equation following? E(weightit)=β0[landcoverit]+β1*percentforestit+β2*sexiE(weight_{}) = \\beta_0[landcover_{}] + \\beta_1*percentforest_{} + \\beta_2 * sex_i yit∼Normal(E(weightit),σ2)y_{} \\sim Normal(E(weight_{}), \\sigma^2) Answer: expected weight individual bear time tt function categorical landcover, percent forest bear’s county sex bear. observed bear weight normal distribution centered around expected weight standard deviation σ\\sigma.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab01b_Mathematical_Notation.html","id":"example-turtles","dir":"Articles","previous_headings":"Math to English","what":"Example: Turtles","title":"Lab1: Mathematical Notation","text":"’m running headstarting experiment spotted turtles Northeastern United States. turtles sexed release. released wild 3 different age groupings (juvenile, subadult, adult). come following potential model explain probability turtle ii survived 6 week study: logit(ϕi)=ϕ0[releaseagei]+ϕ1*birthweightilogit(\\phi_{}) = \\phi_0[releaseage_i] + \\phi_1*birthweight_iyi∼Bernoulli(ϕi)y_i \\sim Bernoulli(\\phi_i) mean English? Answer: probability turtle survived study function age group release turtle’s birthweight. Note yiy_i going binary (0 = didn’t make , 1 = survived).","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab01b_Mathematical_Notation.html","id":"homework-questions","dir":"Articles","previous_headings":"","what":"Homework Questions","title":"Lab1: Mathematical Notation","text":"Write mathematical representation matches following information: expected weight individual bear time tt function categorical landcover, sex bear, time since fire. relationship time since fire different males females. observed bear weight normal distribution centered around expected weight standard deviation σ\\sigma. Note: multiple ways write , just choose one makes sense Looking following bear equation, interpret (english) β1\\beta_1 negative? β2\\beta_2 negative? E(weightit)=β0[landcoverit]+β1*percentforestit+β2*sexiE(weight_{}) = \\beta_0[landcover_{}] + \\beta_1*percentforest_{} + \\beta_2 * sex_i Looking data (Example 2 Lab), notice also recorded turtle’s sex release. Sex recorded either unknown, male female. add information previous turtle model survival probability? (Assume ’s possible turtles sex category age.) 1-10 scale, 1 worst week ever 10 best, rate week’s content? lingering questions/confusion lecture lab still ?","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"what-is-data-simulation","dir":"Articles","previous_headings":"","what":"What is data simulation","title":"Simulating linear regression data","text":"Data simulation technique generating random data stochastic processes known parameters. Although framed “data simulation”, already done several times semester. example, simple data simulation generate random samples normal distribution known mean (μ=3\\mu=3) variance (σ2=0.752=0.5625\\sigma^2=0.75^2 = 0.5625). exercise, ’ll learn simulating data slightly complex models similar ones might use analyze data. example, imagine simple single-season occupancy model probability occupancy ψ=0.75\\psi=0.75 detection probability p=0.4p=0.4. words1: zi∼Bernoulli(ψ)z_i \\sim Bernoulli(\\psi) yi∼Bernoulli(zi×p)y_i \\sim Bernoulli(z_i \\times p) can simulate data set model using lines R code: seven lines code, now fake data set fed occupancy model estimate ψ\\psi pp.","code":"x <- rnorm(100, 3, 0.75) nSites <- 100  # Number of sites nVisits <- 3 psi <- 0.75    # Occupancy probability p <- 0.4       # Detection probability  z <- rbinom(n = nSites, size = 1, prob = psi)     ## Generate true state of each site;                                                   ## nb Bernoulli = binomial with size = 1 y <- rbinom(n = nSites*nVisits, size = 1, prob = z * p)   ## Generate observations y <- matrix(y, nrow = nSites, ncol = nVisits)"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"why-simulate-data","dir":"Articles","previous_headings":"","what":"Why simulate data?","title":"Simulating linear regression data","text":"first, may seem strange generate fake data set just can run modeling exercise get answers already know. data simulation powerful technique toolbox ecological modeler. number reasons data simulation useful2: Truth known: Usually apply model data, don’t know true parameter values generated data. case, may able fit model ’ll never know got right answer. simulated data, can check whether model returns known parameter values. useful way make sure code think ’s . Sampling error: already learned, sampling error inherent part ecological analysis. noise results sampling error makes harder detect true signals process model. real data, single data set, makes hard understand effect sampling error inference. simulated data, can generate hundreds even thousands data sets process/observation models, allowing observe effects sampling error directly. Check characteristics estimators: Related point 1, complex model just single data set ’s difficult determine whether estimators using well-behaved; , return estimates unbiased precise. simulated data, can directly quantify properties. Power analysis: varying effect sizes sample sizes simulated data, can easily perform power analyses. Using simulated data way can useful designing field studies helping interpret inferences data collected analyzed. Check identifiability/estimability parameters: Bayesian models, can always obtain posterior distributions every parameter model. However, posteriors always useful. cases, data may provide little--information value parameter therefore posterior distribution parameter simply determined prior. lack identifiability may caused intrinsic properties model (example, two parameters completely confounded different combinations parameter values likelihood) data provide enough information estimate parameters model (example, regression model dozens predictors observations). Although rigorous methods testing intrinsic identifiability, task can extremely difficult complex hierarchical models. Simulated data allow check whether parameters model can estimated generating replicate data sets properties (sample size, etc) data. Check robustness violations model assumptions: models assumptions data generated. assumptions stem way formulate process observation models. course, assumptions violated degree real data sets. simulated data sets, can generate data know violate assumptions model one ways (e.g., generating heterogeneous survival probabilities model assumes constant survival). comparing parameters estimates “mis-specified” data sets, can gauge degree inferences sensitive violations. Better understand model: One good way test whether really understand model see can write code simulate data model. many cases, exercise uncover misunderstandings lack understanding model actually . Simulating data good way make sure understand parameter model actually represents. can simulate data part model, chances can also figure model may working way think . short, simulating data great way develop deeper understanding model.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"simulating-linear-regression-data","dir":"Articles","previous_headings":"","what":"Simulating linear regression data","title":"Simulating linear regression data","text":"exercise, simulate visualize data generated general process model: linear regression. ’m probably guilty animal focused, assume response variable model counts number seeds produced flowers rare, endangered orchid. ecologists studying orchid, want know whether seed production related number visits orchid’s specialist pollinator. Perhaps , can increase growth rate orchid population boosting abundance pollinator (assuming number visits function pollinator abundance). hypothesize seed number increase linearly pollinator visitation. hypothesis can translated process model: yi=α+β*xi+ϵiy_i = \\alpha + \\beta * x_i + \\epsilon_iϵi∼Normal(0,σ2)\\epsilon_i \\sim Normal(0, \\sigma^2) yiy_i number seeds counted flower ii xix_i number pollinator visits. simplicity, assume record yiy_i xix_i without error. model, α\\alpha β\\beta regression coefficients govern relationship seed counts visitation ϵi\\epsilon_i normally distribution error term. may recognize basic linear regression model single covariate xx. Choosing probability distribution describe seed counts Earlier semester, discussed Poisson distribution default distribution data positive integers (e.g., count data). However, case, choice linear regression implies normally distributed data. choice justified? First , remember linear model composed two parts: response=deterministicpart+stochasticpartresponse = deterministic\\; part+stochastic\\; part distributional assumptions linear model refer residuals (ϵi\\epsilon_i’s). , assume stochastic error response variable (yiy_i) error equally likely produce values larger smaller value predicted deterministic portion model (α+β*xi\\alpha + \\beta * x_i). small counts, Poisson distribution asymmetrical, meaning likely generate values larger mean smaller mean. can see clearly histogram , generated Poisson(λ=2)Poisson(\\lambda = 2):  case, assuming error terms normally distribution likely inappropriate. However, counts get larger, Poisson distribution starts appear “normal”:  case, μ=λ=500\\mu = \\lambda = 500. counts get bigger, little difference results linear regression Poisson GLM. ***","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"step-0-set-up-your-workspace-and-directories","dir":"Articles","previous_headings":"","what":"Step 0: Set up your workspace and directories","title":"Simulating linear regression data","text":"Hopefully already created main directory course started homework assignment last week. already done , create sub-directory folder called data. exercise, create new script add whatever sub-directory use store analysis scripts (alternatively, add script data data-raw folders since ’ll use create data. Just use whatever system makes sense ). next section, copy code markdown file script.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"step-1-set-the-model-parameters","dir":"Articles","previous_headings":"","what":"Step 1: Set the model parameters","title":"Simulating linear regression data","text":"first step simulating data set fixed values needed generate stochastic data. usually includes sample size, covariate parameter values fixed value relevant analysis. case, ’ll first set number flowers counted seeds : Next, need generate covariate values, case pollination visits. ’ll store values data frame assume number visits ranges 0 25: common task data preparation adding new variables derived variables raw data. example, might want add new variable scaled values covariate. analyses, good practice scale covariate values mean 0 extend far 0 (large values (positive negative) can create numerical issues fitting models). next center scale visit covariate (’ll manually also done using built-function scale() simply simulating data normal distribution first place). tidyverse, workhorse adding new variables dplyr::mutate(): can check covariate now mean = 0 sd = 1. NOTE can sometimes confusing know functions come packages (know function R default using). reason, ’s good practice get habit using package::function() syntax, mutate() . Using syntax makes explicit package/function intend use makes code easier understand reduces potential errors. benefit, can stop using library(package) beginning script. Finally, need set parameter values regression models. understanding parameter represents helpful. example, α\\alpha expected number seeds covariate value 0 (centered visits, interpret α\\alpha expected number seeds mean number visits): Now set β\\beta coefficient. already said β\\beta positive (seed count increases visits). ’s left decide specific value. Remember interpret β\\beta additional number seeds 1 sd increase number visits.","code":"N <- 175 # Number of flowers sim_df <- data.frame(visits = runif(N, 0, 25)) # Number of pollination visits sim_df <- dplyr::mutate(sim_df, visits.c = (visits - mean(visits))/sd(visits)) alpha <- 250 # Expected number of seeds at mean number of visits beta <- 50   # Effect of visits on seed count"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"step-2-generate-expected-counts","dir":"Articles","previous_headings":"","what":"Step 2: Generate expected counts","title":"Simulating linear regression data","text":"generate simulated seed counts flower, first calculate μi\\mu_i, expected seeds flower. get values simply plugging observed visitation values site linear model: [μ1μ2μ3...μN]=[1visits11visits21visits3......1visitsN]×[αβ]\\begin{bmatrix}     \\mu_1 \\\\     \\mu_2 \\\\     \\mu_3 \\\\     .\\\\     .\\\\     .\\\\     \\mu_N \\end{bmatrix} = \\begin{bmatrix}     1  & visits_1\\\\     1  & visits_2\\\\     1  & visits_3\\\\     . & .\\\\     . & .\\\\     . & .\\\\     1  & visits_N \\end{bmatrix} \\times \\begin{bmatrix}     \\alpha\\\\     \\beta  \\end{bmatrix} remember matrix algebra, multiplying covariate matrix coefficient matrix : 1×α+visitsi×β1 \\times \\alpha + visits_i \\times \\beta matrix predicted responses called linear predictor. Now refreshed memory basic linear model structure, let’s add predicted seed counts data frame:","code":"sim_df <- dplyr::mutate(sim_df, mu = alpha + beta*visits.c)"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"step-2b-plot-relationships","dir":"Articles","previous_headings":"Step 2: Generate expected counts","what":"Step 2b: Plot relationships","title":"Simulating linear regression data","text":"Whenever simulate data, ’s useful plot data early often. often difficult know ahead time exactly response values complex model produce. Plots great way quickly assess whether simulation producing values consistent domain expertise.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"brief-intro-to-ggplot2","dir":"Articles","previous_headings":"Step 2: Generate expected counts > Step 2b: Plot relationships","what":"Brief intro to ggplot2","title":"Simulating linear regression data","text":"consistent use tidyverse, create plots using ggplot2(). power flexibility ggplot2 come ’s consistent structure. Although bit overwhelming first, get hang structure actually makes quite easy create highly customized publication-quality graphics. plots created using ggplot2 use underlying structure: ggplot⏟initiateplot(data=df⏟dataframe,aes(x=,y=)⏟plotattributes)+geom_line()⏟geometry\\underbrace{ggplot}_{initiate\\; plot}(\\underbrace{data = df}_{data\\;frame},\\; \\underbrace{aes(x =\\; , y = \\;)}_{plot\\; attributes}) + \\underbrace{geom\\_line()}_{geometry} ggplot() function initiates new plot. function, tell ggplot2 data frame using plot tell map attributes data visual properties figures. Attributes mapped inside aes() argument. Attributes usually include location (x-axis y-axis placement), color, size, shape, line type, many others. general, attribute mapped one column data frame. ggplot() function simply initiates graph run just portion code get blank graph. can see creating new plot showing relationship elevation (x-axis plot) predicted abundance (y-axis):  can see ggplot created figure correct axes labels. data. ’s didn’t tell ggplot type geometry use represent data. Geometry refers actual type geometric object(s) want use display data. Common geometries include points (e.g., scatterplot), lines (e.g., time series), bars (e.g., histograms). many others. add geometry, can see data:  can see model predicts seed counts ranging 171.66 individuals 337.96. reasonable? knows, made species. wasn’t, good time go back play different parameter values generate abundances consistent domain expertise. example, model predicts ≈\\approx 171.66 seeds flower 0 pollination visits. Maybe makes sense (perhaps orchids can self-pollinate necessary) maybe doesn’t. doesn’t, need re-think model structure.","code":"ggplot(data = sim_df, aes(x = visits, y = mu)) ggplot(data = sim_df, aes(x = visits, y = mu)) + geom_point()"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"step-3-generate-the-actual-seed-counts","dir":"Articles","previous_headings":"","what":"Step 3: Generate the actual seed counts","title":"Simulating linear regression data","text":"far, simulated seed counts contain stochastic variation (visitation covariate stochastic given value, predicted counts completely deterministic). create realistic data set, need add process variance (σp2\\sigma^2_p). example, requires setting another parameter controls amount process variation. Now simply generate random seed counts using linear predictor process variation  expected, seed count increases μ\\mu, though can see process variation added model stage.","code":"sigma <- 7.5 ### Generate actual abundance for each site sim_df <- dplyr::mutate(sim_df, y = rnorm(n = N, mu, sigma))  ### Plot lambda vs. N ggplot(data = sim_df, aes(x = mu, y = y)) + geom_point() +   scale_x_continuous(expression(mu[i])) +   scale_y_continuous(expression(y[i])) +   geom_abline(slope = 1, intercept = 0)"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"step-4-save-the-simulated-data","dir":"Articles","previous_headings":"","what":"Step 4: Save the simulated data","title":"Simulating linear regression data","text":"Now simulated data set, let’s save ’s available future use. many ways save objects R one well-behaved saveRDS(). want use object future, run3:","code":"saveRDS(object = sim_df, file = \"data/sim_seed_counts.rds\") sim_df <- readRDS(\"data/sim_seed_counts.rds\")"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"homework-questions-part-1-easier","dir":"Articles","previous_headings":"","what":"Homework Questions Part 1 (Easier)","title":"Simulating linear regression data","text":"performing study deer CWD want simulate 20 years abundance data declining population. general sense population declining average 5% year (e.g. E(Nt+1)=NtλtE(N_{t+1}) = N_t\\lambda_t), realized population stochasticity (Nt+1∼Pois(E(Nt+1))N_{t+1} \\sim Pois(E(N_{t+1}))). population year 1 475 deer. Write simulation data use ggplot visualize realized population values across 20 years. Use set.seed() command make reproducible. decide add complexity simulation λt\\lambda_t vary time. real data collected 1994 2016, ’ll use environmental data time period. think lambda might positive relationship degree days (daily average number degrees 4 C) December year (e.g. λt=exp(l0+l1*degreedays)\\lambda_t = exp(l_0 + l_1*degreedays). Using ‘Weather_data’ provided WILD8370 package (accessed via: data(Weather_data) ), simulate 20 years population abundance. sure choose reasonable values l0l_0 l1l_1 λt\\lambda_t stays 1.1 values degree days. Don’t forget scale covariate! Use ggplot visualize realized population values across 20 years. (Note: years multiple weather stations recording degree days, use average weather stations covariate)","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab2_simulation.html","id":"homework-questions-part-2-slightly-harder","dir":"Articles","previous_headings":"","what":"Homework Questions Part 2 (Slightly Harder)","title":"Simulating linear regression data","text":"GPS data leopard frogs want fit random-walk movement model. However, use real data, want make fake data set first can use develop full model. want simulation contain: locations (1 per day 50 days, continuous coordinates). day location measured (day 1 day 50) plan fit following model: si,x,t=1∼Uniform(0,1)s_{,x,t=1} \\sim Uniform(0, 1) si,y,t=1∼Uniform(0,1)s_{,y,t=1} \\sim Uniform(0, 1) si,x,t+1∼Normal(si,x,t,σ2)s_{, x, t+1} \\sim Normal(s_{, x, t}, \\sigma ^2 ) si,y,t+1∼Normal(si,y,t,σ2)s_{, y, t+1} \\sim Normal(s_{, y, t}, \\sigma^2 ) σ∼Exp(3)\\sigma \\sim Exp(3) ii individual, xx yy x y coordinates respectively, σ\\sigma related frog’s average movement previous location. , location frog time t+1t+1 normal centered around location time tt. assume ’ll 10 frogs dataset. Simulate data based model. Store results 3-d array matrix (10 2 50) realize ’ll need adjust simulation adjust model. Wrap simulation function allow run simulation different values σ\\sigma number frogs return simulated movements. (E.g. Sim <- function(sigma, nfrogs)) 1-10 scale, 1 worst week ever 10 best, rate week’s content? lingering questions/confusion lecture lab still ?","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab3_BasicMCMC.html","id":"markov-chain-monte-carlo","dir":"Articles","previous_headings":"","what":"Markov chain Monte Carlo","title":"Lab 3: Basic MCMC","text":"basic steps Metropolis sampler : Choose initial value θ\\theta (call θ1\\theta^1) Propose new value θ*\\theta^* proposal distribution Compute probability accepting θ*\\theta^* using joint distributions evaluated θ*\\theta^* previous value θk−1\\theta^{k-1} Accept θ*\\theta* (.e., θk=θ*\\theta^{k} = \\theta^*) probability estimated step 2, otherwise retain previous value (.e., θk=θk−1\\theta^{k} = \\theta^{k-1}","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab3_BasicMCMC.html","id":"why-bother","dir":"Articles","previous_headings":"","what":"Why Bother?","title":"Lab 3: Basic MCMC","text":"First, let’s simulate fake data binomial distribution example. Maybe ’re flipping coin want know ’s fair. flip 20 times results get: Let’s take look data table: Looks like 16 zeros (“failures”) 4 1’s (“successes”). Probably fair coin. want estimate probability success? truly fair, ’d expect probability 0.5. reallllllly wanted , try figure entire “hand” guessing bunch values using probability density function binomial distribution tell us close correct value. ’s might look: know equation binomial distribution size 20 : 20!(20−X!)X!(pX)(1−p)20−X\\frac{20!}{(20-X!)X!}(p^X)(1-p)^{20-X} go finding p? Well, start, ’s probability density 4 successes p = .1? Okay, high. p = .4? Hmm, little lower. p = .7? Oof, lower . eventually ’d see numbers larger (yay) smaller (less good answers). guessed enough numbers, ’d probably find highest say p pretty close whatever value . Obviously picking random values p hand isn’t efficient. Let’s function us graph result :  can see value p probably close .3 ’s highest probability density , can also see method tried bunch points (AKA wastes lot time) around values basically know aren’t going good answers. instance, ’re pretty sure coin isn’t going success probability .9, kind prefer model spend much time testing values . way function spend time “good” areas, trying estimate exact value p less time “bad” areas answer unlikely? equations math isn’t just one distribution bunch distributions combined? yes! ’s called MCMC. makes ineffective plug--chug methods much faster.","code":"set.seed(20) x <- rbinom(20, size = 1, prob = .2) x #>  [1] 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 table(x) #> x #>  0  1  #> 16  4 dbinom(4, 20, .1) #> [1] 0.08978 dbinom(4, 20, .4) #> [1] 0.03499 dbinom(4, 20, .7) #> [1] 5.008e-06 pick.ps <- function(n){   p <- runif(n, min = 0, max = 1)   d <- dbinom(4,20,p)   return(data.frame(p = p, d=d)) }"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab3_BasicMCMC.html","id":"seed-count-model","dir":"Articles","previous_headings":"","what":"Seed count model","title":"Lab 3: Basic MCMC","text":"generated seed count data, assuming linear model linked pollination visits seed counts: yi=α+β*xi+ϵiy_i = \\alpha + \\beta * x_i + \\epsilon_iϵi∼Normal(0,σ2)\\epsilon_i \\sim Normal(0, \\sigma^2) model includes 3 random variables want estimate posterior distributions : α\\alpha, β\\beta, σ2\\sigma^2 (remember yiy_i xix_i observed therefore treated fixed known rather random variables governed probability distributions). : [α,β,σ2|yi]∝[yi|α,β,σ2][α][β][σ2][\\alpha, \\beta, \\sigma^2|y_i] \\propto [y_i|\\alpha, \\beta, \\sigma^2][\\alpha][\\beta][\\sigma^2] \\tag{1} Sticking data generating model, can define likelihood model using Normal distribution. given values α\\alpha, β\\beta, σ2\\sigma^2, estimate likelihood : [yi|α,β,σ]=∏=1NNormal(yi|α+β×xi,σ2)[y_i|\\alpha, \\beta, \\sigma] = \\prod_{=1}^N Normal(y_i|\\alpha + \\beta \\times x_i, \\sigma^2) α\\alpha, β\\beta, σ2\\sigma^2 random variables, must define prior distributions . α\\alpha β\\beta can positive negative real numbers (’ll ignore now know sign data generating model), can use normal priors: [α]=Normal(α|0,50)[\\alpha] = Normal(\\alpha|0, 50) [β]=Normal(β|0,50)[\\beta] = Normal(\\beta|0, 50) relatively non-informative priors intercept slope coefficients. also need model σ\\sigma. Side note: lot MCMC codes (BUGS language) model normal distribution Normal(mean,precision)Normal(mean, precision) precision = (1/σ21/\\sigma^2). σ\\sigma, use relatively diffuse gamma prior: [σ]=Gamma(σ|1,1)[\\sigma] = Gamma(\\sigma|1, 1)","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab3_BasicMCMC.html","id":"custom-functions","dir":"Articles","previous_headings":"","what":"Custom functions","title":"Lab 3: Basic MCMC","text":"iteration sampler, need perform set tasks, namely estimating likelihood joint distributions proposed current parameter values. copying pasting code necessary calculations point sampler code need . However, time find copying pasting code twice, ’s good idea consider wrapping code function, .","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab3_BasicMCMC.html","id":"function-for-calculating-likelihood","dir":"Articles","previous_headings":"Custom functions","what":"Function for calculating likelihood","title":"Lab 3: Basic MCMC","text":"Given values α\\alpha, β\\beta, σ\\sigma, can estimate likelihood R using dnorm() function (note take sum log likelihoods rather product likelihoods avoid numerical issues): turn code function, first open new script call calc_like.R. Save R/ sub-directory. script contain function code. function code : allows us put data (y), covariate values (x), values α\\alpha, β\\beta, σ\\sigma arguments function return log likelihood. Save code script close script.","code":"# Calculate the predicted count for each flower   lp <- alpha + beta * x      # Calculate the likelihood of our data given the model   sum(dnorm(y, lp, sigma, log = TRUE)) calc_like <- function(y, alpha, beta, sigma, x) {   lp <- alpha + beta * x   ll <- sum(dnorm(y, lp, sigma, log = TRUE))   return(ll) }"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab3_BasicMCMC.html","id":"functions-for-calculating-prior-probabilities","dir":"Articles","previous_headings":"Custom functions","what":"Functions for calculating prior probabilities","title":"Lab 3: Basic MCMC","text":"also need functions estimate prior probabilities specific values α\\alpha, β\\beta, σ\\sigma. Create new script titled priors.R save R/ sub-directory. following functions take values parameter estimate prior probability given prior distributions defined :","code":"priorAlpha <- function(alpha, mu = 0, sigma = 50){   prob <- dnorm(alpha, mu, sigma, log = TRUE)   return(prob) }   priorBeta <- function(beta, mu = 0, sigma = 50){   prob <- dnorm(beta, mu, sigma, log = TRUE)   return(prob) }   priorsigma <- function(sigma, shape1 = 0.1, rate1 = 0.1){   prob <- dgamma(sigma, shape = shape1, rate = rate1, log = TRUE)   return(prob) }"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab3_BasicMCMC.html","id":"metropolis-sampler","dir":"Articles","previous_headings":"Custom functions","what":"Metropolis sampler","title":"Lab 3: Basic MCMC","text":"Now ready create sampler. Remember multiple parameters, need define full conditionals. random variable model, define full conditional including element right hand side eq. 1 contains parameter (note change σ\\sigma): [α|.]=[yi|α,β,σ][α][\\alpha|.] = [y_i|\\alpha, \\beta, \\sigma][\\alpha][β|.]=[yi|α,β,σ][β][\\beta|.] = [y_i|\\alpha, \\beta, \\sigma][\\beta] [σ|.]=[yi|α,β,σ][σ][\\sigma|.] = [y_i|\\alpha, \\beta, \\sigma][\\sigma] sampler, loop parameter, going Metropolis steps treating parameters known (based current value chain). clear, walking R code hopefully make concrete (don’t worry trying copy run code section, simply illustration. next section, slightly modify code run sampler seed count data). First, set length chains, set tuning parameter proposal distribution, create empty data frame store samples binary variable estimating acceptance rate: Next, randomly generate initial values parameter. Remember quite big numbers data generating model create initial values magnitude: final “set ” step estimate likelihood data given initial values. , use calc_like() function created earlier: Now create actual sampler. , create loop implements steps iteration chains. , simply go step make sure understand ’s . ’ll start going Metropolis steps α\\alpha (though remember order doesn’t matter): Let’s go line line. step 1a, generate new value α\\alpha normal distribution centered previous value. Remember tuning parameter set earlier determines big jumps current proposed values. step 1b, use calc_like() function estimate likelihood data given new value α\\alpha previous values β\\beta σ\\sigma. mean say treat parameters fixed known. step 1c, estimate joint probability current proposed values adding log likelihood log prior probability (note sum log values product probabilities). step 1d, estimate probability accepting new value. Note proposed value likely current value (R>1R > 1), function return 1. Otherwise, returns ratio. closer joint probabilities , closer RR 1. less likely proposed value relative current value, smaller RR . means much less likely accept new values α\\alpha lot less probable current value (though impossible). Finally, step 1e accept reject proposed value. Note compare RR random value generated Uniform(0,1)Uniform(0,1) distribution. R=1R=1, always greater value always accept proposed value (mcmc_df$alpha[] <- cand) update current likelihood match current value α\\alpha. R<1R<1, turns testing whether RR less randomly generated value Uniform(0,1)Uniform(0,1) ensures accept α\\alpha probability RR (’ll leave prove based properties uniform distribution). Next thing β\\beta, using new value alphaalpha (mcmc_df$alpha[]) previous value σ\\sigma (mcmc_df$sigma[- 1]): Finally, update σ\\sigma using new values α\\alpha β\\beta. difference σ\\sigma >0>0, normal proposal distribution used α\\alpha β\\beta work (create negative values). learned lecture, create proposal distribution generates positive value (e.g., gamma) use moment matching estimate parameters regards current σ\\sigma tuning parameter. ’ll use slightly less efficient approach demonstrate different ways enforcing behavior want sampler. cases, simply add small value current σ\\sigma automatically reject proposed value ’s less 0. small value can negative positive allow us explore posterior.","code":"## Length of chains   nIter <- 10000  ## Tuning parameter   tuning <- 1.5  ## Empty data frame to store posterior samples of each parameter   mcmc_df <- data.frame(x = 1:nIter,                         alpha = numeric(nIter),                         beta = numeric(nIter),                         sigma = numeric(nIter),                         accept.alpha = 0,                         accept.beta = 0,                         accept.sigma = 0) ## Initial values   mcmc_df$alpha[1] <-  runif(1, 200, 300)   mcmc_df$beta[1] <- runif(1, 25, 75)   mcmc_df$sigma[1] <- runif(1, 0, 10) ## Initial likelihood likelihood <- calc_like(y = y, alpha = mcmc_df$alpha[1],                         beta = mcmc_df$beta[1], sigma = mcmc_df$sigma[1],                         x = x) ######################## #### 1. Update alpha ########################  ## 1a: Generate candidate value   cand <- rnorm(1, mcmc_df$alpha[i - 1], tuning)  ## 1b: Calculate likelihood at candidate value   cand_like <- calc_like(y = y, alpha = cand, beta = mcmc_df$beta[i-1], sigma = mcmc_df$sigma[i-1], x = x)    ## 1c: Calculate likelihood * prior at old value and candidate value   jointOld <- likelihood + priorAlpha(mcmc_df$alpha[i-1])    jointCand <- cand_like + priorAlpha(cand)     ## 1d: Acceptance probability    R <- min(1, exp(jointCand - jointOld))  ## 1e: Decide whether to accept or not   if(R > runif(1)) {   # if accepted       mcmc_df$alpha[i] <- cand       likelihood <- cand_like     } else {       mcmc_df$alpha[i] <- mcmc_df$alpha[i-1]   } ######################## #### 2. Update beta ########################  ## 2a: Generate candidate value   cand <- rnorm(1, mcmc_df$beta[i - 1], tuning)  ## 2b: Calculate likelihood at candidate value   cand_like <- calc_like(y = y, alpha = mcmc_df$alpha[i], beta = cand,                           sigma = mcmc_df$sigma[i-1], x = x)    ## 2c: Calculate likelihood * prior at old value and candidate value   jointOld <- likelihood + priorBeta(mcmc_df$beta[i-1])    jointCand <- cand_like + priorBeta(cand)     ## 2d: Acceptance probability    R <- min(1, exp(jointCand - jointOld))  ## 2e: Decide whether to accept or not   if(R > runif(1)) {   # if accepted       mcmc_df$beta[i] <- cand       likelihood <- cand_like     } else {       mcmc_df$beta[i] <- mcmc_df$beta[i-1]     } ######################## #### 3. Update sigma ########################  ## 3a: Generate candidate value     cand <- mcmc_df$sigma[i-1] + runif(1,  -.1, 0.1)     # If candidate value is outside [0,Inf], keep the old value of sigma     if (cand < 0) {       mcmc_df$sigma[i] <- mcmc_df$sigma[i-1]     } else { ## 3b: Calculate likelihood at candidate value       cand_like <- calc_like(y = y, alpha = mcmc_df$alpha[i], beta = mcmc_df$beta[i],                            sigma = cand, x = x)        ## 3c: Calculate likelihood * prior at old value and candidate value       jointOld <- likelihood + priorsigma(mcmc_df$sigma[i-1])       jointCand <- cand_like + priorsigma(cand)  ## 3d: Acceptance probability        R <- min(1, exp(jointCand - jointOld))  ## 3e: Decide whether to accept or not       if(R > runif(1)) {   # if accepted         mcmc_df$sigma[i] <- cand         likelihood <- cand_like       } else {         mcmc_df$sigma[i] <- mcmc_df$sigma[i-1]       }     }   }"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab3_BasicMCMC.html","id":"running-the-sampler","dir":"Articles","previous_headings":"","what":"Running the sampler","title":"Lab 3: Basic MCMC","text":"Finally, can run sampler. Create new script called metroplis.R (something similar) put scripts/. First, load packages need use source() function read custom functions (source() runs .R files given argument case make functions available sampler): Next, read simulated data set initial values MCMC: Now take sampler code put inside loop create chains. Note likelihood functions need reference simulated data covariates: point, able run script start finish create posterior samples parameter.","code":"library(WILD6900)  source(\"R/calc_like.R\") source(\"R/priors.R\") ## Read simulated data   sim_dat <- readRDS(\"data/sim_seed_counts.rds\")  ## Length of chains   nIter <- 10000  ## Tuning parameter   tuning <- 1.5  ## Empty data frame to store posterior samples of each parameter   mcmc_df <- data.frame(x = 1:nIter,                         alpha = numeric(nIter),                         beta = numeric(nIter),                         sigma = numeric(nIter),                         accept.alpha = 0,                         accept.beta = 0,                          accept.sigma = 0)  ## Initial values   mcmc_df$alpha[1] <-  runif(1, 200, 300)   mcmc_df$beta[1] <- runif(1, 25, 75)   mcmc_df$sigma[1] <- runif(1, 0, 10)    ## Initial likelihood   likelihood <- calc_like(y = sim_dat$y, alpha = mcmc_df$alpha[1],                         beta = mcmc_df$beta[1], sigma = mcmc_df$sigma[1],                         x = sim_dat$visits.c) for(i in 2:nIter){ ######################## #### 1. Update alpha ########################  ## 1a: Generate candidate value   cand <- rnorm(1, mcmc_df$alpha[i - 1], tuning)  ## 1b: Calculate likelihood at candidate value   cand_like <- calc_like(y = sim_dat$y, alpha = cand,                           beta = mcmc_df$beta[i-1], sigma = mcmc_df$sigma[i-1],                           x = sim_dat$visits.c)    ## 1c: Calculate likelihood * prior at old value and candidate value   jointOld <- likelihood + priorAlpha(mcmc_df$alpha[i-1])    jointCand <- cand_like + priorAlpha(cand)     ## 1d: Acceptance probability    R <- min(1, exp(jointCand - jointOld))  ## 1e: Decide whether to accept or not   if(R > runif(1)) {   # if accepted       mcmc_df$alpha[i] <- cand       likelihood <- cand_like       mcmc_df$accept.alpha[i] <- 1     } else {       mcmc_df$alpha[i] <- mcmc_df$alpha[i-1]     }    ######################## #### 2. Update beta ########################  ## 2a: Generate candidate value   cand <- rnorm(1, mcmc_df$beta[i - 1], tuning)  ## 2b: Calculate likelihood at candidate value   cand_like <- calc_like(y = sim_dat$y, alpha = mcmc_df$alpha[i], beta = cand,                           sigma = mcmc_df$sigma[i-1], x = sim_dat$visits.c)    ## 2c: Calculate likelihood * prior at old value and candidate value   jointOld <- likelihood + priorBeta(mcmc_df$beta[i-1])    jointCand <- cand_like + priorBeta(cand)     ## 2d: Acceptance probability    R <- min(1, exp(jointCand - jointOld))  ## 2e: Decide whether to accept or not   if(R > runif(1)) {   # if accepted       mcmc_df$beta[i] <- cand       likelihood <- cand_like       mcmc_df$accept.beta[i] <- 1     } else {       mcmc_df$beta[i] <- mcmc_df$beta[i-1]     }    ######################## #### 3. Update sigma ########################  ## 3a: Generate candidate value     cand <- mcmc_df$sigma[i-1] + runif(1,  -1, 1)     # If candidate value is outside [0,Inf], keep the old value of sigma     if (cand < 0) {       mcmc_df$sigma[i] <- mcmc_df$sigma[i-1]     } else { ## 3b: Calculate likelihood at candidate value       cand_like <- calc_like(y = sim_dat$y, alpha = mcmc_df$alpha[i], beta = mcmc_df$beta[i],                            sigma = cand, x = sim_dat$visits.c)        ## 3c: Calculate likelihood * prior at old value and candidate value       jointOld <- likelihood + priorsigma(mcmc_df$sigma[i-1])       jointCand <- cand_like + priorsigma(cand)  ## 3d: Acceptance probability        R <- min(1, exp(jointCand - jointOld))  ## 3e: Decide whether to accept or not       if(R > runif(1)) {   # if accepted         mcmc_df$sigma[i] <- cand         likelihood <- cand_like         mcmc_df$accept.sigma[i] <- 1       } else {         mcmc_df$sigma[i] <- mcmc_df$sigma[i-1]       }     } }"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab3_BasicMCMC.html","id":"checking-the-output","dir":"Articles","previous_headings":"","what":"Checking the output","title":"Lab 3: Basic MCMC","text":"Now can determine whether sampler returns data generating values data simulation. assessing output MCMC chains, good first diagnostic usually checking trace plots:  chain α\\alpha moved rapidly initial value stationary posterior distribution first samples obviously bias parameter estimates include posterior. Let’s remove using dplyr function slice():  looks better. Now can estimate mean 95% credible interval posterior: Pretty close data generating value 250. Now let’s check β\\beta:  Also pretty close data generating value 50. Finally, σ\\sigma  Wasn’t easy?","code":"ggplot(mcmc_df, aes(x = x, y = alpha)) + geom_path() mcmc_df <- dplyr::slice(mcmc_df, 1000:nIter)  ggplot(mcmc_df, aes(x = x, y = alpha)) + geom_path() mean(mcmc_df$alpha) #> [1] 251.3 quantile(mcmc_df$alpha, probs = c(0.025, 0.975)) #>  2.5% 97.5%  #> 250.2 252.4 ggplot(mcmc_df, aes(x = x, y = beta)) + geom_path() mean(mcmc_df$beta) #> [1] 49.1 quantile(mcmc_df$beta, probs = c(0.025, 0.975)) #>  2.5% 97.5%  #> 48.02 50.17 ggplot(mcmc_df, aes(x = x, y = sigma)) + geom_path() mean(mcmc_df$sigma) #> [1] 7.424 quantile(mcmc_df$sigma, probs = c(0.025, 0.975)) #>  2.5% 97.5%  #> 6.690 8.254"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab3_BasicMCMC.html","id":"homework","dir":"Articles","previous_headings":"","what":"Homework","title":"Lab 3: Basic MCMC","text":"simulation, set α\\alpha = 250, provided reasonable, diffuse prior example . happens give restrictive (wrong) prior α\\alpha? Change priorAlpha function instead match α∼Uniform(0,150)\\alpha \\sim Uniform(0, 150). Make sure also change line match new prior: Run sampler print chain α\\alpha. see? Go back original prior alpha. didn’t discuss much lab, tuning parameter affects fast sampler explore state space. ’s really small, might take forever. ’s really large, can make giant jumps reject lot possible values, wastes time causes sampler ‘stall’. can see acceptance rate sampler calculating mean accept.alpha, accept.beta accept.sigma columns. Run sampler tuning parameter .05 50. Calculate acceptance rates 3 parameters. notice?","code":"mcmc_df$alpha[1] <-  runif(1, 200, 300) #change this to something reasonable"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab3_BasicMCMC.html","id":"homework-1-bonus-point","dir":"Articles","previous_headings":"","what":"Homework (+1 Bonus Point)","title":"Lab 3: Basic MCMC","text":"generated seed count data, assuming linear model linked pollination visits seed counts: yi=α+β*xi+ϵiy_i = \\alpha + \\beta * x_i + \\epsilon_i. used simulated data, know model ahead time. However real life, wouldn’t know true model ahead time might try fit different model data. Adding already , create MCMC also includes second beta term looks visits squared: yi=α+β*xi+β2*xi2+ϵiy_i = \\alpha + \\beta * x_i + \\beta_2 * x_i^2 + \\epsilon_i. Run MCMC look output. MCMC estimate β2\\beta_2? Hint: Approach problem one step time. - Begin changing mcmc_df allow store additional beta parameter. - Next, choose initial value beta2. - Change calc_like function include beta2. Remember lp just alpha + betax + beta2x*x. - Optionally, create another function priorBeta2 (just re-use priorBeta function beta2 well). Next create section sampler update Beta2. look almost identical one already present Beta. - Run model. - Finally, use quantile function look estimate: quantile(mcmc_df$beta2, probs = c(0.025,0.5, 0.975)) 1-10 scale, 1 worst week ever 10 best, rate week’s content? lingering questions/confusion lecture lab still ?","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab4_glms.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"GLMs for modeling count data","text":"data activity comes long-term project monitored population peregrine falcons nesting French Jura 1964 2003 1.  Load inspect data: falcons dataframe 4 columns: Year: year (integer). Pairs: number adult pairs (integer). R.pairs: number reproductive pairs (integer). Eyasses: number fledged young (integer).","code":"library(WILD8370) data(\"falcons\") head(falcons)"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab4_glms.html","id":"analysis-1-change-in-population-size","dir":"Articles","previous_headings":"","what":"Analysis 1: Change in population size","title":"GLMs for modeling count data","text":"first model fit examines change number adult falcon pairs time. Plotting data shows change linear:  short decline beginning study period, population increased dramatically perhaps reaching carrying capacity.","code":"ggplot(falcons, aes(x = Year, y = Pairs)) + geom_point() + stat_smooth(se = FALSE)"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab4_glms.html","id":"modeling-non-linear-effects-using-linear-models","dir":"Articles","previous_headings":"Analysis 1: Change in population size","what":"Modeling non-linear effects using linear models","title":"GLMs for modeling count data","text":"can model non-linear change abundance , definition, linear models model linear effects? Using polynomials! Remember equation curved line single peak (bottom): $$\\Large y = + b \\times x + c \\times x^2$$  aa maximum (minimum) value yy, bb value xx maximum (minimum) occurs cc determines whether peak maximum (c<0c<0) minimum (c>0c>0). can add complex shape adding additional polynomial terms. example, including cubic term creates s-shaped curve: $$\\Large y = + b \\times x + c \\times x^2 + d \\times x^3$$  Including polynomial terms linear predictor model gives us enormous flexibility model non-linear relationships using GLMs.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab4_glms.html","id":"modeling-change-in-falcon-counts","dir":"Articles","previous_headings":"Analysis 1: Change in population size","what":"Modeling change in falcon counts","title":"GLMs for modeling count data","text":"build model falcon data, need define components required GLMs (distribution, link function, linear predictor). counts, natural choice distribution : Ct∼Poisson(λt)C_t \\sim Poisson(\\lambda_t) CtC_t observed count year tt λt\\lambda_t expected count. learned lecture, conventional link function count data log-link: log(λt)=log(E(λt))log(\\lambda_t) = log(E(\\lambda_t)) Finally, need write linear predictor. Based preliminary visualization data, cubic polynomial might appropriate capture non-linear change time: log(λt)=α+β1×yeart+β2×yeart2+β3×yeart3log(\\lambda_t) = \\alpha + \\beta_1 \\times year_t + \\beta_2 \\times year^2_t + \\beta_3 \\times year^3_t","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab4_glms.html","id":"accessing-and-viewing-the-nimble-model","dir":"Articles","previous_headings":"Analysis 1: Change in population size","what":"Accessing and viewing the Nimble model","title":"GLMs for modeling count data","text":"can copy paste following code R script. file, can see use relatively non-informative normal priors regression coefficients. can also see likelihood statement similar linear regression model last lecture, minor differences. First, assume observed falcon counts come Poisson distribution, use dpois(lambda[]) rather dnorm(mu[], tau). Also, apply log-link function predicted counts (log(lambda[])=...). Notice Nimble allows model transformed predicted counts left hand side linear predictor equation Lab Questions Plot histogram random samples normal prior used model (remember convert precision 0.33 standard deviation). can see, vague normal priors used past. advantage using less-vague normal priors? linear regression model fit last lecture, also prior τ\\tau, (inverse) process variance. include parameter model? Creating lambda[] object strictly necessary since deterministic function year. wanted fewer lines code, include linear predictor directly inside dpois() function instead lambda[], though need appropriately transform linear predictor. transformation use put linear predictor count scale?","code":"library(nimble) falcon_mod <- nimbleCode({   # Priors   alpha ~ dnorm(0, 0.33)   beta1 ~ dnorm(0, 0.33)   beta2 ~ dnorm(0, 0.33)   beta3 ~ dnorm(0, 0.33)    # Likelihood   for (i in 1:n){     C[i] ~ dpois(lambda[i])     log(lambda[i]) <- alpha + beta1 * year[i] + beta2 * pow(year[i],2) + beta3 * pow(year[i],3)   } #end i })"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab4_glms.html","id":"fitting-the-model","dir":"Articles","previous_headings":"Analysis 1: Change in population size","what":"Fitting the model","title":"GLMs for modeling count data","text":"fitting model, need prepare input Nimble includes: storing data named list storing constants named list creating function randomly generate initial values parameter creating vector parameters want Nimble monitor set MCMC settings ’ve mentioned several times, ’s often bad idea include covariate values far 0. reason, first scale year mean=0mean=0 sd=1sd=1: Now ’re ready run model. easiest way run Nimble model run one command: However, sometimes (get advanced), ’ll want able customize Nimble runs little bit . ’s also much easier error check initial values models take long time run run step step. ’s look like one chain: View portion results (printing lambda values takes much room): Note beta2 appears cross 0 - ’s much effect year^2 lambda. seems reasonable, let’s make sure Rhat values less 1.1. , ’ll use gelman.diag() function coda package. parameters appear converged. usual, let’s check trace plots see look:  monitoring lambda can also plot predicted counts along observed counts. First, need calculate posterior means upper/lower bounds 95% credible interval add falcons data frame, use ggplot visualize:","code":"year <- (falcons$Year - mean(falcons$Year))/sd(falcons$Year)  nimdat <- list(C = falcons$Pairs)  nimconsts <- list(year = year, n = nrow(falcons))  niminits <- function(){list(alpha = rnorm(1), beta1 = rnorm(1), beta2 = rnorm(1), beta3 = rnorm(1))}  params <- c(\"alpha\", \"beta1\", \"beta2\", \"beta3\", \"lambda\")  nC <- 3 #chains  nI <- 10000 #iterations  nB <- 2500 #burnin  nT <- 1 #thin falcon_res <- nimbleMCMC(code = falcon_mod,                      data = nimdat,                      constants = nimconsts,                      inits = niminits(),                      monitors = params,                      thin = nT,                      niter = nI,                      nburnin = nB,                      nchains = nC,                      samplesAsCodaMCMC = TRUE                       ) #> |-------------|-------------|-------------|-------------| #> |-------------------------------------------------------| #> |-------------|-------------|-------------|-------------| #> |-------------------------------------------------------| #> |-------------|-------------|-------------|-------------| #> |-------------------------------------------------------| prepnim <- nimbleModel(code = falcon_mod, constants = nimconsts,                            data = nimdat, inits = niminits(), calculate = T) prepnim$initializeInfo() #will tell you what is or isn't intialized prepnim$calculate() #if this is NA or -Inf you know it's gone wrong mcmcnim <- configureMCMC(prepnim, monitors = params, print = T) nimMCMC <- buildMCMC(mcmcnim) #actually build the code for those samplers Cmodel <- compileNimble(prepnim) #compiling the model itself in C++; Compnim <- compileNimble(nimMCMC, project = prepnim) # compile the samplers next Compnim$run(niter = nI, nburnin = nB, thin = nT) falcon_res <- (as.mcmc(as.matrix(Compnim$mvSamples))) summary(falcon_res[,c('alpha', 'beta1', 'beta2', 'beta3', 'lambda[1]', 'lambda[2]', 'lambda[3]')])$quantiles library(coda) gelman.diag(falcon_res, multivariate = F)$psrf[1:10,] #don't want to print out all 40 lambdas #>           Point est. Upper C.I. #> alpha          1.004      1.014 #> beta1          1.016      1.056 #> beta2          1.003      1.010 #> beta3          1.016      1.058 #> lambda[1]      1.004      1.015 #> lambda[2]      1.003      1.010 #> lambda[3]      1.001      1.004 #> lambda[4]      1.000      1.001 #> lambda[5]      1.000      1.000 #> lambda[6]      1.001      1.003 # View traceplots for alpha, beta1, beta2, and beta3 (not for lambda) plot(falcon_res[,params[-5],]) #get the quantiles for just the lambda parameters: lambdas <- summary(falcon_res[,paste0('lambda[', 1:40, ']')])$quantiles   falcons <- dplyr::mutate(falcons, lambda = lambdas[,3],                                    q2.5 = lambdas[,1],                                    q97.5 = lambdas[,5])  ggplot(falcons) +    geom_ribbon(aes(x = Year, ymin = q2.5, ymax = q97.5), fill = \"grey90\") +   geom_path(aes(x = Year, y = lambda), color = \"red\") +   geom_point(aes(x = Year, y = Pairs)) +   scale_y_continuous(\"Pairs\")"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab4_glms.html","id":"analysis-2-nest-success-model","dir":"Articles","previous_headings":"","what":"Analysis 2: Nest success model","title":"GLMs for modeling count data","text":"Next, let’s use falcons data set fit another type GLM - binomial GLM. Hopefully exercise show ’re comfortable writing coding GLM components (distribution, link function, linear predictor), extremely easy fit models different distributional assumptions. estimate reproductive success (.e., probability pair successfully produces offspring), model number reproductive pairs (falcons$R.Pairs) function total number pairs (falcons$Pairs). total number reproductive pairs exceed total number pairs, counts falcons$.RPairs bounded less falcons$Pairs. case, Poisson distribution appropriate count model. Instead, use binomial distribution: Ct∼binomial(Nt,pt)C_t \\sim binomial(N_t, p_t) goal model ptp_t, probability nesting successfully year. case, log link appropriate - ptp_t bound 0 1. probabilities, logit link generally appropriate link function: logit(pt)=log(pt1−pt)logit(p_t) = log\\bigg(\\frac{p_t}{1-p_t}\\bigg) Following Kéry & Schaub, ’ll model probability quadratic function year: logit(pt)=α+β1×yeart+β2×yeart2logit(p_t) = \\alpha + \\beta_1 \\times year_t + \\beta_2 \\times year^2_t last example, can copy code . Note Nimble order arguments binomial probability size, unlike type R: , prepare data run model:","code":"pairs_mod <- nimbleCode({   # Priors   alpha ~ dnorm(0, 0.33)   beta1 ~ dnorm(0, 0.33)   beta2 ~ dnorm(0, 0.33)    # Likelihood   for (t in 1:nyears){     C[t] ~ dbinom(p[t], N[t])     logit(p[t]) <- alpha + beta1 * year[t] + beta2 * pow(year[t],2)   } #end i }) #using standardized year from above nimdat2 <- list(C = falcons$R.Pairs) nimconsts2 <- list(N = falcons$Pairs, year = year, nyears = nrow(falcons)) niminits2 <- function(){list(alpha = rnorm(1), beta1 = rnorm(1), beta2 = rnorm(1))}  params2 <- c(\"alpha\", \"beta1\", \"beta2\", \"p\")  nC <- 3  nI <- 10000  nB <- 2500  nT <- 1  pairs_res <- nimbleMCMC(code = pairs_mod,                      data = nimdat2,                      constants = nimconsts2,                      inits = niminits2(),                      monitors = params2,                      thin = nT,                      niter = nI,                      nburnin = nB,                      nchains = nC,                      samplesAsCodaMCMC = TRUE                       ) #> |-------------|-------------|-------------|-------------| #> |-------------------------------------------------------| #> |-------------|-------------|-------------|-------------| #> |-------------------------------------------------------| #> |-------------|-------------|-------------|-------------| #> |-------------------------------------------------------| summary(pairs_res[,c('alpha', 'beta1', 'beta2', 'p[1]', 'p[2]', 'p[3]')])$quantiles # View traceplots for alpha, beta1, and beta2(not for p) plot(pairs_res[,params2[-4],]) ps <- summary(pairs_res[,paste0('p[', 1:40, ']')])$quantiles  falcons <- dplyr::mutate(falcons, p = ps[,3],                                    q2.5_p = ps[,1],                                    q97.5_p = ps[,5])  ggplot(falcons) +    geom_ribbon(aes(x = Year, ymin = q2.5_p, ymax = q97.5_p), fill = \"grey90\") +   geom_path(aes(x = Year, y = p), color = \"red\") +   geom_point(aes(x = Year, y = R.Pairs/Pairs)) +   scale_y_continuous(\"Pairs\")"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab4_glms.html","id":"homework-questions","dir":"Articles","previous_headings":"","what":"Homework Questions","title":"GLMs for modeling count data","text":"Using ’ve learned lab, write model expected number nestlings (Eyasses) per reproducing pair (R.pairs) year. Begin writing mathematical formulation model Write Nimble code. Provide model data, constants initial values Check output convergence Display ggplot showing expected number nestlings per reproducing pair year (95% credible interval) vs raw data. Don’t forget title axis labels. may help plot data first see type data working :  second analysis, used binomial GLM describe proportion successful peregrine pairs per year French Jura mountains. see connections three important types GLMs, first use Poisson GLM model number successful pairs (thus disregarding fact binomial total varies year), second, use normal GLM . graph, compare predicted numbers successful pairs every year three models (binomial, Poisson, normal GLMs). [assignment stolen directly WinBUGS book, blame Marc Kéry Michael Schaub one.] Note: find normal distribution model predicts extremely low counts, sure look priors. selected correctly, see 3 models roughly overlap raw data. 1-10 scale, 1 worst week ever 10 best, rate week’s content? lingering questions/confusion lecture lab still ?","code":"ggplot(falcons, aes(x = Year, y = Eyasses/R.Pairs))+   geom_line(lwd = 1, lty = 2)+   geom_point()+   geom_smooth()"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"objectives","dir":"Articles","previous_headings":"","what":"Objectives","title":"Lab6: Missing Data","text":"Analyze data using random fixed effects Deal missing data Gain experience Nimble","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"european-hares","dir":"Articles","previous_headings":"","what":"European Hares","title":"Lab6: Missing Data","text":"Data today comes Swiss hare data included Marc Kéry’s 2010 book, Introduction WinBUGS Ecologists. data contain replicated counts Brown hares (Lepus europaeus) conducted 17 years (1992-2008) 56 sites 8 regions Switzerland.year, two counts conducted two-week period. Sites vary area, elevation, belong two types habitat (arable grassland). can read study : https://www.sciencedirect.com/science/article/pii/S0006320710004921?via=ihub  Let’s begin taking look data: now, let’s focus hares Central region. can start simple model random effects binomial observation process. Since count data, natural choice process model poisson log link. Perhaps hare abundance affected size site (area) landuse type (landuse) detection probability different different sites (site1). Let ii site (site1) study area surveyed year tt.: log(λi,t)=β0+β1[landusei]+β2*areai log(\\lambda_{,t}) = \\beta_0 + \\beta_1[landuse_i] + \\beta_2*area_{} Ni,t∼Pois(λi,t) N_{,t} \\sim Pois(\\lambda_{,t})  , let yy represent number hares observed survey kk given year: yi,t,k∼Binomial(Ni,t,pi) y_{,t,k} \\sim Binomial(N_{,t}, p_{}) pi=ln(α[site]1−α[site]) p_i = ln(\\frac{\\alpha[site]}{1-\\alpha[site]}) (Remember writing ln(x1−x)ln(\\frac{x}{1-x}) logit(f(x)). )","code":"data(\"swiss_hares\") head(hares) #>   no site     region    site2 area elevation landuse year count1 count2 #> 1  1 AG01 CH.Central Reusstal 2.23       384  arable 1992     NA     NA #> 2  2 AG01 CH.Central Reusstal 2.23       384  arable 1993     NA     NA #> 3  3 AG01 CH.Central Reusstal 2.23       384  arable 1994     NA     NA #> 4  4 AG01 CH.Central Reusstal 2.23       384  arable 1995      6      4 #> 5  5 AG01 CH.Central Reusstal 2.23       384  arable 1996      7      5 #> 6  6 AG01 CH.Central Reusstal 2.23       384  arable 1997      3      3 #>   mean.density #> 1           NA #> 2           NA #> 3           NA #> 4        2.691 #> 5        3.139 #> 6        1.345 library(dplyr) Central_hares <- hares %>% filter(region == 'CH.Central')"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"building-the-nimble-model","dir":"Articles","previous_headings":"","what":"Building the Nimble model","title":"Lab6: Missing Data","text":"can less work backwards mathematical model write nimble model. Ignoring correct formatting, : Now can just add loops get indexing correct choose priors. Let’s start making landuse fixed effect. Now can get data, constants, inits ready.","code":"library(nimble) library(coda) nimbleCode({   #Process model    log(lambda[i,t]) <- beta0 + beta1[landuse[i]] + beta2*site_area[i]    N[i,t] ~ dpois(lambda[i,t])        #observation model    y[i,t,k] ~ dbinom(size = N[i,t],p =p[i])    logit(p[i]) <- alpha[site[i]] }) hare_mod <- nimbleCode({   for(i in 1:nsites){     for(t in 1:nyears){       #Process model       log(lambda[i,t]) <- beta0 + beta1[landuse[i]] + beta2*site_area[i]       N[i,t] ~ dpois(lambda[i,t])              for(k in 1:2){ #could also do 1:ncounts[t] if we wanted to be fancy         #observation model         y[i,t,k] ~ dbinom(size = N[i,t],p =p[i])       }     }     logit(p[i]) <- alpha[site[i]]   } #priors:   beta0 ~ dnorm(0, 1)   beta2 ~ dnorm(0, 1)   for(m in 1:nlandtypes){     beta1[m] ~ dnorm(0, 1)   }   for(j in 1:nsites){     alpha[j] ~ dnorm(0, 1)   } })"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"in-class-question","dir":"Articles","previous_headings":"Building the Nimble model","what":"In Class Question","title":"Lab6: Missing Data","text":"parameters need initial values? parameters objects need included constants?","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"missing-data-values","dir":"Articles","previous_headings":"Building the Nimble model","what":"Missing Data Values","title":"Lab6: Missing Data","text":"Now come across common issue - missing data. sites surveyed years. ? cut years sites surveyed, ’d end throwing away lot data. ’re also still going need deal sites surveyed given year. solve , can adjust code also include parameter effort indicating site surveyed session. effort 0, detections survey round also 0 (since didn’t survey). Based code, see need observations 3-d array, sites rows, time columns sessions (1 2) third dimension. easy way turn character strings numbers first turn factors, convert numeric. can create empty array y (counts) effort (binary indicating surveyed). Now can fill arrays using… wait … -loops!","code":"hare_mod <- nimbleCode({   for(i in 1:nsites){     for(t in 1:nyears){       #Process model       log(lambda[i,t]) <- beta0 + beta1[landuse[i]] + beta2*site_area[i]       N[i,t] ~ dpois(lambda[i,t])              for(k in 1:2){ #could also do 1:ncounts[t] if we wanted to be fancy         #observation model         y[i,t,k] ~ dbinom(size = N[i,t],p =p[i]*effort[i,t,k])       }     }          logit(p[i]) <- alpha[site[i]]   } #priors:   beta0 ~ dnorm(0, 1)   beta2 ~ dnorm(0, 1)   for(m in 1:nlandtypes){     beta1[m] ~ dnorm(0, 1)   }   for(j in 1:nsites){     alpha[j] ~ dnorm(0, 1)   } }) Central_hares$site_n <- as.numeric(as.factor(Central_hares$site)) y <- array(0, dim = c(length(unique(Central_hares$site_n)),                                 length(1992:2008),                                  2)) effort <- array(1, dim = c(length(unique(Central_hares$site_n)),                                 length(1992:2008),                                  2)) for(i in 1:nrow(Central_hares)){   mysite <- Central_hares$site_n[i]   myyear <- Central_hares$year[i] - 1991 #so that year 1 will be 1992   y[mysite, myyear, ] <- c(Central_hares$count1[i], Central_hares$count2[i]) } effort[is.na(y)] <- 0 #if y is NA, we didn't survey y[is.na(y)] <- 0 #if y is NA, that means our count is 0  hare.dat <- list(y =y) #for nimble"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"constants","dir":"Articles","previous_headings":"Building the Nimble model","what":"Constants","title":"Lab6: Missing Data","text":"nimble need separate data (stochastic known information) constants (unchanging known information). Let’s make constants list next.","code":"constants_prep <- Central_hares %>%     mutate(landuse_n = as.numeric(factor(landuse))) %>%     group_by(site) %>%     summarize(         landuse = first(landuse_n),  # Get the landuse type for each site         area = first(area),        # Get the area for each site         .groups = \"drop\"           # To remove grouping after summarizing     ) constants_prep$area_s <- scale(constants_prep$area) #scale the area head(constants_prep) #> # A tibble: 6 × 4 #>   site  landuse  area area_s[,1] #>   <chr>   <dbl> <dbl>      <dbl> #> 1 AG01        1  2.23    -0.861  #> 2 AG02        1  3.58    -0.573  #> 3 AG03        1  4.79    -0.315  #> 4 AG04        1  5.8     -0.0999 #> 5 LU01        2 16.5      2.18   #> 6 LU07A       2  5.85    -0.0892 hare.consts <- list(nsites = length(unique(Central_hares$site_n)),                     nyears = length(1992:2008),                      landuse = constants_prep$landuse,                     site_area = c(constants_prep$area_s), #remove the 'attributes' part                     site = 1:nrow(constants_prep),                     effort = effort,                     nlandtypes = 2)"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"initial-values","dir":"Articles","previous_headings":"Building the Nimble model","what":"Initial Values","title":"Lab6: Missing Data","text":"Now need initialize model. Reminder need initialize anything comes distribution already known. case, means N, beta0, beta1, beta2 alpha need initial values. many ways initialize model, easy way often set betas 0 except intercepts. N, know y result N*p, can start N max(y)/p site.","code":"N.init <- array(NA, dim = c(hare.consts$nsites, hare.consts$nyears)) for(i in 1:nrow(N.init)){   N.init[i,] <- max(y[i,,])/.5  #can use .5 b/c the mean of the prior alpha is 0, which becomes p = .5     } hare.inits <- list(beta0 = rnorm(1, 0, 1), #match the prior                    beta1 = rep(0, 2), #effect of two land types                    beta2 = 0, #effect of area                    alpha = rnorm(hare.consts$nsites, 0, 1), #match prior                    N = N.init                    )"},{"path":[]},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"parallel-processing","dir":"Articles","previous_headings":"Run the Model","what":"Parallel Processing","title":"Lab6: Missing Data","text":"past, ’ve run Nimble 3 chains, one . fine, means wait chain finished start next one. save time, let’s run three chains time using computer’s multi-core system. work, ’ll need use parallel package R. several ways run parallel chains R, ’s preferred method. begin loading parallel coda packages R, using makeCluster() command prepare run three chains parallel Next export needed information cluster. includes initial values, data, constants, model code. Finally, put relevant parts model run clusterEvalQ() function. like method can first test code indivdiually running line inside function run together ’re positive ’ve de-bugged everything. computer, takes minute. ’ve run model parallel, ’s good practice close Cluster.","code":"library(parallel) cl <- makeCluster(3) #each chain will be run separately  library(coda) clusterExport(cl = cl, varlist = c(\"hare.inits\", \"hare.dat\", \"hare.consts\", \"hare_mod\")) hares.out <- clusterEvalQ(cl = cl,{ library(nimble) #reload packages for each core library(coda) #Specify params: pars = c('beta0', 'beta1', 'beta2', 'alpha', 'N')  prepnim <- nimbleModel(code = hare_mod, constants = hare.consts,                            data = hare.dat, inits = hare.inits, calculate = T) prepnim$initializeInfo() #will tell you what is or isn't initialized prepnim$calculate() #if this is NA or -Inf you know it's gone wrong mcmcnim <- configureMCMC(prepnim, monitors = pars, print = T) nimMCMC <- buildMCMC(mcmcnim) #actually build the code for those samplers Cmodel <- compileNimble(prepnim) #compiling the model itself in C++; Compnim <- compileNimble(nimMCMC, project = prepnim) # compile the samplers next Compnim$run(niter = 150000, nburnin = 50000, thin = 2) res <- (as.mcmc(as.matrix(Compnim$mvSamples))) return(res)  }) #this will take awhile and not produce any progress bar.  #You know it's done when the hares.out object is created in your environment. hares.out <- as.mcmc.list(hares.out) stopCluster(cl)"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"inspecting-output","dir":"Articles","previous_headings":"","what":"Inspecting Output","title":"Lab6: Missing Data","text":"Let’s take look model told us. can start beta alpha values. can use grep function select variables don’t contain word ‘N’ (abundance) . case, ’ll ask R column names first list (chain 1) use grep tell us names contains ‘N’. ’ll save parameters without N new object. Let’s plot beta values using MCMCvis package Oh dear. alpha parameters look great, beta parameters look pretty terrible. can see chains lot trouble mixing. Often can happen parameters identifiable. ’s pretty easy see happen - effect area abundance 0, ’d left equation says abundance sum two numbers without information ’s impossible solve variables! aren’t sure two parameters correlated (potentially unidentifiable), can graph correlation chains using mcmcOutput package. plot, can see beta0 strong negative correlation (-1) beta1[1] beta1[2]. good.","code":"betas <- hares.out[,-grep('N', colnames(hares.out[[1]])),] library(MCMCvis) MCMCvis::MCMCtrace(betas, pdf = F) library(mcmcOutput) mcmcOutput::crosscorrPlot(betas[,8:11,], addSpace = c(0, 1))"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"re-write-the-model","dir":"Articles","previous_headings":"","what":"Re-write the Model","title":"Lab6: Missing Data","text":"Let’s fix model removing beta0. also need remove initial value beta0 inits object. Time re-run. Grab alpha beta params plot Much better!","code":"hare_mod <- nimbleCode({   for(i in 1:nsites){     for(t in 1:nyears){       #Process model       log(lambda[i,t]) <- beta1[landuse[i]] + beta2*site_area[i]       N[i,t] ~ dpois(lambda[i,t])              for(k in 1:2){ #could also do 1:ncounts[t] if we wanted to be fancy         #observation model         y[i,t,k] ~ dbinom(size = N[i,t],p =p[i]*effort[i,t,k])       }     }          logit(p[i]) <- alpha[site[i]]   } #priors:   beta2 ~ dnorm(0, 1)   for(m in 1:nlandtypes){     beta1[m] ~ dnorm(0, 1)   }   for(j in 1:nsites){     alpha[j] ~ dnorm(0, 1)   } }) hare.inits$beta0 <- NULL cl <- makeCluster(3) #each chain will be run separately  clusterExport(cl = cl, varlist = c(\"hare.inits\", \"hare.dat\", \"hare.consts\", \"hare_mod\")) hares.out <- clusterEvalQ(cl = cl,{ library(nimble) #reload packages for each core library(coda) #Specify params: pars = c('beta1', 'beta2', 'alpha', 'N') #removed beta0  prepnim <- nimbleModel(code = hare_mod, constants = hare.consts,                            data = hare.dat, inits = hare.inits, calculate = T) prepnim$initializeInfo() #will tell you what is or isn't initialized prepnim$calculate() #if this is NA or -Inf you know it's gone wrong mcmcnim <- configureMCMC(prepnim, monitors = pars, print = T) nimMCMC <- buildMCMC(mcmcnim) #actually build the code for those samplers Cmodel <- compileNimble(prepnim) #compiling the model itself in C++; Compnim <- compileNimble(nimMCMC, project = prepnim) # compile the samplers next Compnim$run(niter = 150000, nburnin = 50000, thin = 2) res <- (as.mcmc(as.matrix(Compnim$mvSamples))) return(res)  }) #this will take awhile and not produce any progress bar.  #You know it's done when the hares.out object is created in your environment. hares.out <- as.mcmc.list(hares.out) stopCluster(cl) betas <- hares.out[,-grep('N', colnames(hares.out[[1]])),] MCMCvis::MCMCtrace(betas, pdf = F)"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"random-effects","dir":"Articles","previous_headings":"","what":"Random Effects","title":"Lab6: Missing Data","text":"point, ’ve treating detection probability fixed effect site. , expected similarity detection probabilities different sites. Let’s try model random effect instead see changes estimates. , let’s grab current model’s alpha values can see compare. Okay, now model: See works? use random effect, ’re saying average effect 0, site’s specific beta higher lower. amount variation mean controlled sd.site, require prior . can describe alpha parameter sd.site ‘hyper-parameter.’ Time update inits object value sd.site. Run model : Let’s check alpha parameters version model:  seem mixed nicely. compare modeled alpha fixed effect? Let’s make quick graph compare.  can see numerically spread alphas little smaller second model.","code":"alphas1 <-  hares.out[,grep('alpha', colnames(hares.out[[1]])),] hare_mod <- nimbleCode({   for(i in 1:nsites){     for(t in 1:nyears){       #Process model       log(lambda[i,t]) <- beta1[landuse[i]] + beta2*site_area[i]       N[i,t] ~ dpois(lambda[i,t])              for(k in 1:2){ #could also do 1:ncounts[t] if we wanted to be fancy         #observation model         y[i,t,k] ~ dbinom(size = N[i,t],p =p[i]*effort[i,t,k])       }     }          logit(p[i]) <- alpha[site[i]]   } #priors:   beta2 ~ dnorm(0, 1)   for(m in 1:nlandtypes){     beta1[m] ~ dnorm(0, 1)   }   for(j in 1:nsites){     alpha[j] ~ dnorm(0, sd = sd.site) #this is the change   }   sd.site ~ dexp(3) }) hare.inits$sd.site <- rexp(1,1)  #from the prior cl <- makeCluster(3) #each chain will be run separately  clusterExport(cl = cl, varlist = c(\"hare.inits\", \"hare.dat\", \"hare.consts\", \"hare_mod\")) hares.out <- clusterEvalQ(cl = cl,{ library(nimble) #reload packages for each core library(coda) #Specify params: pars = c('beta1', 'beta2', 'sd.site', 'alpha', 'N') #add sd.site  prepnim <- nimbleModel(code = hare_mod, constants = hare.consts,                            data = hare.dat, inits = hare.inits, calculate = T) prepnim$initializeInfo() #will tell you what is or isn't initialized prepnim$calculate() #if this is NA or -Inf you know it's gone wrong mcmcnim <- configureMCMC(prepnim, monitors = pars, print = T) nimMCMC <- buildMCMC(mcmcnim) #actually build the code for those samplers Cmodel <- compileNimble(prepnim) #compiling the model itself in C++; Compnim <- compileNimble(nimMCMC, project = prepnim) # compile the samplers next Compnim$run(niter = 250000, nburnin = 150000, thin = 2) res <- (as.mcmc(as.matrix(Compnim$mvSamples))) return(res)  }) #this will take awhile and not produce any progress bar.  #You know it's done when the hares.out object is created in your environment. hares.out <- as.mcmc.list(hares.out) stopCluster(cl) alphas2 <- hares.out[,grep('alpha', colnames(hares.out[[1]])),] MCMCvis::MCMCtrace(alphas2, pdf = F) mod1_alphas <- summary(alphas1)$quantiles  mod2_alphas <- summary(alphas2)$quantiles gg_alphas <- data.frame(param = rep(paste0('alpha', 1:7), 2),                         LCI = c(mod1_alphas[,1], mod2_alphas[,1]),                         Median = c(mod1_alphas[,3], mod2_alphas[,3]),                         UCI = c(mod1_alphas[,5], mod2_alphas[,5]),                         Model = rep(c(\"Fixed Effect\", \"Random Effect\"), each = 7)) library(ggplot2) ggplot(gg_alphas, aes(x = param, y = Median, col = Model))+   geom_pointrange(aes(ymin = LCI, ymax = UCI), position=position_dodge(width = .25))+   xlab(\"Parameter\")+   scale_color_manual(values = c('#7C94EC', '#C88B37'))+   geom_hline(yintercept = mean(mod1_alphas[,3]), lty = 2, col = '#7C94EC')+   geom_hline(yintercept = mean(mod2_alphas[,3]), lty = 2, col = '#C88B37')+   theme(axis.text.x = element_text(angle = 30, hjust = .75)) var(mod1_alphas[,3]) #> [1] 0.4704 var(mod2_alphas[,3]) #> [1] 0.3972"},{"path":"http://rushinglab.github.io/WILD8370/articles/Lab6_MissingData.html","id":"homework","dir":"Articles","previous_headings":"","what":"Homework","title":"Lab6: Missing Data","text":"lab example, just looked hares central region. Using entire dataset, fit two working model ran - one detection random effect site one fixed effect. Use ggplot create graph showing difference parameter estimates calculate variance mean alpha parameter value. change variance two models compare lab run just subset data? data formally analyzed, authors used random effect year process model random effect site detection process. Run model random effects. Use ggplot compare beta1 values (effect landuse type expected abundance) produced new mode vs model Question 1. site average area (scaled area = 0), expected abundance land use type? Since abundance model, makes sense make plot abundance time. Inside model used Question 2, create 2 derived parameterS represents total abundance sites landtype (one parameter landtype) year. Use ggplot graph estimated total average density landtype time, including CIs. (Note: get density, determine total area plots landtype, divide estimates number). practice converting model code mathematical notation expected scientific paper, write model Question 2 full mathematical form, including priors. 1-10 scale, 1 worst week ever 10 best, rate week’s content? lingering questions/confusion lecture lab still ?","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"what-is-markdown","dir":"Articles","previous_headings":"","what":"What is Markdown?","title":"Introduction to R Markdown","text":"discuss R Markdown , need discuss Markdown . Markdown? Let’s start ’s . Many probably created report paper using word processor like Microsoft Word Google Docs. Word processors referred “see get” (wysiwyg) text editors. means highlight text click boldface icon Word, text appears bold screen. sorts formatting options, including making headers, inserting figures, adding page numbers, etc., possible clicking buttons. code behind scenes creates changes users don’t see code, formatting output. makes wysiwyg editors relatively easy use beginners. advanced users, can actually problematic. ever Word act ways don’t fully understand? course! . ever tried opening .docx file using older version Word, find doesn’t look way thought ? ever inserted figure jump another page get ‘anchored’ bottom page? just problems occur document bunch hidden formatting code see understand. Markdown different. Markdown files plain text files, meaning can created edited using text editors (like NotePad Windows TextEdit Mac). biggest difference Markdown files Word documents formatting Markdown documents occurs document rather behind scenes. make something boldface tell Markdown putting two **asterisks** either side word phrase. Italics done putting one *asterisk* around text. Hyperlinks written like : [Hyperlinks](https://en.wikipedia.org/wiki/Markdown). just many formatting options can include Markdown document. ’ll learn options like headers, lists, mathematical symbols equations, figures later tutorial throughout semester. ’re writing, text won’t look bold italic whatever (‘see get’, ’s ‘see type’). formatting shows render Markdown file create another type document (pdf, html, even Word). nice thing Markdown uses standard ways express specific formatting options, can convert documents different output formats easily.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"what-is-r-markdown","dir":"Articles","previous_headings":"","what":"What is R Markdown?","title":"Introduction to R Markdown","text":"course, use specific ‘flavor’ Markdown called ‘R Markdown’. R Markdown gives us formatting options available Markdown plus ability embed, display, run R code documents. mixing R code plain text, can create dynamic reports replicate analytical processes, show code underlying processes, create output analysis (figures, summary statistics, etc.), provide necessary text explanations go along code output.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"why-use-r-markdown","dir":"Articles","previous_headings":"","what":"Why use R Markdown","title":"Introduction to R Markdown","text":"R Markdown many advantages compared creating reports Word GoogleDocs. advantages include: Versatility- Want convert Word document pdf? ’s hard. pdf Word? ’s pain. PDF HTML? Maybe know don’t. R Markdown, can change formats single click (single line code). can even convert pretty nice slide shows. Embed code text - running analysis, get results Word? Type hand? Copy--paste? pain error prone. Rerun analysis using new data? Oops, now copy paste new results figures. R Markdown, embed code directly text results figures get added reports automatically. means copying pasting updating reports new results come . Annotate code - Using # great adding small annotations R scripts definitely get habitat . sometimes need add lot details help users (future self) make sense complex code. R Markdown allows create documents much text formatting need, along code. Version control - Tired saving manuscript_v1.doc, manuscript_v2.doc, manuscript_final.doc, manuscript_final_v2.doc? version control . won’t go specifics R Markdown allows seamlessly use version control systems like git Github document changes reports. Edit text files - R Markdown files easily created edited within RStudio don’t way. can opened edited base R even using text editors. means can create edit platform (Windows, Mac, Linux) using free software already installed computer Stability - many us Word crash ’re working paper? save working? Hope . R Markdown files smaller lightweight, tend cause computer crash ’re working . Focus text, formatting - spend lot time tweaking formatting Word document rather writing? R Markdown allows separate writing process formatting process, allows focus former without worrying later (theory least). Plus lots templates can use ensure formatting taken care without anything special!","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"why-not-use-r-markdown","dir":"Articles","previous_headings":"","what":"Why not use R Markdown?","title":"Introduction to R Markdown","text":"disadvantages R Markdown. adviser doesn’t use - Try sending .Rmd file adviser get feedback. ’ll wait… Like , folks still use word processors, adopt R Markdown still create edit Word documents collaborators stuck ways track changes - Even ’re lucky adviser review .Rmd file, won’t get nice track changes like Word. alternative (version control helps) none quite easy track changes. Fewer formatting options - better worse, limited set formatting options R Markdown. can constraining (often ’s actually freeing!) ’s learning curve - already know use Word. R Markdown new. make something bold? insert equations? get figures go end document? first, almost certainly google almost every thing need R Markdown (number 1 problem). pretty simple still means going can slow first.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"creating-a-new-r-markdown-file","dir":"Articles","previous_headings":"","what":"Creating a new R Markdown file","title":"Introduction to R Markdown","text":"Click File -> New File -> R Markdown... Choose title format (HTML, pdf, Word) document Click Ok Save newly created document Pretty easy","code":""},{"path":[]},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"the-yaml-header","dir":"Articles","previous_headings":"Basic formatting","what":"The YAML header","title":"Introduction to R Markdown","text":"top .Rmd file, see several line three blue dashes: called “YAML header” ’s can control lot major formatting options documents. example, change output pdf, just switch html_document pdf_document (note, may need install Latex distribution knit pdf. get error message step, see suggestions ) click Knit button Pretty cool, right? YAML header allows control many “high level” options document. example, change font size, type following directly output: pdf_document argument: Check see font size changed clicking Knit. Changing font type little trickier. Behind scenes, R Markdown turns document Latex code, converted pdf. don’t need know much Latex (though little knowledge helpful) conversion mean formatting options passed Latex converter specific ways. tell Latex want use Arial font, modify output: argument follows: Make sure include spaces indent pdf_document: latex_engine: xelatex. indent first line paragraph, add following header: many possible options header (see additional examples). ’ll learn options later semester.","code":"--- title: \"Test document\" author: \"Clark Rushing\" output: html_document --- fontsize: 12pt title: \"FANR6750\" subtitle: \"Homework 1\" author: \"YOUR NAME HERE\" date: \"2025-02-03\" output:    pdf_document:     latex_engine: xelatex  mainfont: Arial indent: true"},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"content-headers","dir":"Articles","previous_headings":"Basic formatting","what":"Content headers","title":"Introduction to R Markdown","text":"Using headers natural way break document report smaller sections. can include headers putting one # signs front text. One # main header, ## secondary header, etc.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"paragraph-and-line-breaks","dir":"Articles","previous_headings":"Header 1","what":"Paragraph and line breaks","title":"Introduction to R Markdown","text":"writing chunks text R Markdown (e.g., report manuscript), can create new paragraphs leaving empty line paragraph: want force line break, include two spaces end line want break:","code":"This is one paragraph.  This is the next paragraph This is one line   This is the next line"},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"bold-italics","dir":"Articles","previous_headings":"Header 1","what":"Bold, Italics","title":"Introduction to R Markdown","text":"mentioned earlier, create boldface surrounding text two asterisks (**bold**) use single asterisks italics (*italics*)","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"code-type","dir":"Articles","previous_headings":"Header 1","what":"Code type","title":"Introduction to R Markdown","text":"highlight code (note, actually insert functioning code, just formats text show code rather plain text), surround text back ticks: mean() can include multiple lines code including three back ticks line code three back ticks line code:","code":"Multiple lines of code look like  this"},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"bulleted-lists","dir":"Articles","previous_headings":"Header 1","what":"Bulleted lists","title":"Introduction to R Markdown","text":"Bulleted lists can included starting line asterisk can also start lines single dash - sub-sub-bullets, indent twice (press tab two times) start -","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"numbered-lists","dir":"Articles","previous_headings":"Header 1","what":"Numbered lists","title":"Introduction to R Markdown","text":"Numbered lists look like can also include sub-levels number lists can lower case roman numerals lowercase letters B. uppercase letters","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"quotations","dir":"Articles","previous_headings":"Header 1","what":"Quotations","title":"Introduction to R Markdown","text":"highlight quotations starting line >, produces: models wrong useful (George E.P. Box)","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"hyperlinks","dir":"Articles","previous_headings":"Header 1","what":"Hyperlinks","title":"Introduction to R Markdown","text":"Insert hyperlinks putting text want displayed square brackets followed link parentheses: [RStudio cheatsheet](https://www.rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf)","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"equations","dir":"Articles","previous_headings":"Header 1","what":"Equations","title":"Introduction to R Markdown","text":"Inserting equations R Markdown knowing Latex really comes handy equations written using Latex code. part, difficult need insert complex equations probably need look code symbols. many good resources including feeling particularly ambitious .","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"inline-vs--block-equations","dir":"Articles","previous_headings":"Header 1 > Equations","what":"Inline vs. block equations","title":"Introduction to R Markdown","text":"can include equations either inline (e=mc2e = mc^2) stand-alone block: e=mc2e=mc^2 Inline equations added putting single dollar sign $ either side equation ($e=mc^2$). Equation blocks create starting ending new line double dollar signs $$e=mc^2$$","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"greek-letters","dir":"Articles","previous_headings":"Header 1","what":"Greek letters","title":"Introduction to R Markdown","text":"Statistical models include lot Greek letters (α,β,γ\\alpha, \\beta, \\gamma, etc.). can add Greek letters equation typing backslash \\ followed name letter \\alpha. Uppercase lower case letters possible capitalizing name (Δ\\Delta = $\\Delta$) (δ\\delta = $\\delta$).","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"subscripts-and-superscripts","dir":"Articles","previous_headings":"Header 1","what":"Subscripts and superscripts","title":"Introduction to R Markdown","text":"can add superscripts using ^ (πr2\\pi r^2=$\\pi r^2$) symbol subscripts using underscore _ (NtN_t = $N_t$). superscript subscript includes one character, put entire script within curly brackets {}: Nt−1≠Nt−1N_t-1 \\neq N_{t-1} $N_t-1 \\neq N_{t-1}$","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"brackets-and-parentheses","dir":"Articles","previous_headings":"Header 1","what":"Brackets and parentheses","title":"Introduction to R Markdown","text":"can add normal sized brackets parenthesis just typing equation: (x+y)(x + y) = (x + y) need bigger sizes, using $\\big($, $\\bigg($, $\\Bigg($ produces (\\big(, (\\bigg(, (\\Bigg( (switch opening parenthesis closing parenthesis square bracket needed)","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"fractions","dir":"Articles","previous_headings":"Header 1","what":"Fractions","title":"Introduction to R Markdown","text":"Fractions can either inline (1/n1/n = $1/n$) stacked (1n\\frac{1}{n} = $\\frac{1}{n}$). stacked equations, terms first curly brackets numerator terms second curly brackets denominator.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"operators","dir":"Articles","previous_headings":"Header 1","what":"Operators","title":"Introduction to R Markdown","text":"Pretty much every operator need can written latex. common ones include ×\\times ($\\times$), <\\lt ($\\lt$), >\\gt ($\\gt$), ≤\\leq ($\\leq$), ≥\\geq ($\\geq$), ≠\\neq ($\\neq$), ∑\\sum ($\\sum$), ∏\\prod ($\\prod$), ∞\\infty ($\\infty$), ∝\\propto ($\\propto$). See documents Equations section list operators.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"adding-code","dir":"Articles","previous_headings":"","what":"Adding code","title":"Introduction to R Markdown","text":"ability format create pdf html documents great real strength R Markdown ability include run code within document. Code can included inline chunks","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"inline-code","dir":"Articles","previous_headings":"Adding code","what":"Inline code","title":"Introduction to R Markdown","text":"Inline code useful including (simple) R output directly text. Inline code can added enclosing R code `r `. example, typing `r mean(c(3,7,4,7,9))` compute print mean given vector. , print 6 instead code . can useful including summary statistics reports. example, vector indicating number individuals captured occasion mark-recapture study (e.g., n <- c(155, 132, 147, 163)) want include number occasions report, instead typing 4, can type `r length(n)`. prevent typos, extremely useful length(n) might change future. Instead manually changing number occasions, just re-render document new number occasions printed automatically.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"code-chunks","dir":"Articles","previous_headings":"Adding code","what":"Code chunks","title":"Introduction to R Markdown","text":"complicated code, generally useful use chunks inline code. Chunks start separate line ```{r} end ``` line (instead manually, can click Insert button top right script window, click R). two lines, can include many lines code want. example, ```{r}n1 <- 44     # Number individuals captured first occasionn2 <- 32     # Number individuals captured second occasionm2 <- 15     # Number previously marked individuals captured second occasionN <- n1 * n2 / m2     # Lincoln-Peterson estimate abundance```","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"chunk-options","dir":"Articles","previous_headings":"Adding code > Code chunks","what":"Chunk options","title":"Introduction to R Markdown","text":"Code chunks can take lot options control code run displayed documents. options go {r closing } (see options put cursor {r, hit space bar, hit tab). example: echo = FALSE shows output code code include = FALSE runs code display code output (useful chunks read format data) eval = FALSE shows code run (useful showing code) warning = FALSE message = FALSE can include ensure error messages warnings printed, can useful cleaning appearance documents cache = TRUE save results R code doesn’t rerun chunk unless code changed (useful chunks take long time run) .height .width control size figures pdf document inches centimeters (e.g., `.height = “3in”, notice quotation marks) See main R Markdown page complete list possible options.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"setting-defaults-for-all-chunks","dir":"Articles","previous_headings":"Adding code > Code chunks","what":"Setting defaults for all chunks","title":"Introduction to R Markdown","text":"Often useful set default behavior chunks rather including, example, warning = FALSE beginning one. , can include chunk beginning document: ```{r include = FALSE}opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE)``` options can included chuck set default behaviors. can -ride defaults within chunks needed. can also load common packages chunk streamline chunks later document.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"tables","dir":"Articles","previous_headings":"Adding code > Code chunks","what":"Tables","title":"Introduction to R Markdown","text":"nicely print matrices data frames R Markdown document, use kable() function: Table 1: Automobile data 1974 Motor Trends US. kableExtra package provides even advanced options creating nice looking tables. See overview options provided package.","code":"library(knitr) kable(head(mtcars), caption= 'Table 1: Automobile data from 1974 *Motor Trends US*.',       align = 'l')"},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"figures","dir":"Articles","previous_headings":"Adding code > Code chunks","what":"Figures","title":"Introduction to R Markdown","text":"can also easily produce figures directly RMarkdown file. , simple demonstration produce many better looking figures throughout semester. Figure 1: Automobile mpg function horsepower.","code":"plot(mtcars$hp, mtcars$mpg)"},{"path":"http://rushinglab.github.io/WILD8370/articles/RMarkdown.html","id":"additional-resources","dir":"Articles","previous_headings":"","what":"Additional resources","title":"Introduction to R Markdown","text":"RStudio tool bar, click Help -> Cheatsheets select R Markdown cheat sheet (lots good cheat sheets well) RStudio’s R Markdown tutorial Tom Edward’s R Markdown tutorial Coding Club’s Getting Started R Markdown Cosma Shalizi’s Using R Markdown Class Reports","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/graphics.html","id":"attributes-of-good-figures","dir":"Articles","previous_headings":"","what":"Attributes of good figures","title":"Checklist and tips for publication-quality graphics in R","text":"Effective data visualizations : Tell story. figure manuscript report communicate one main findings want readers know. casual reader able understand primary findings looking figures. intuitive. Strive figures readers can understand without read caption text. Readers least grasp main gist figure just looking . Err towards simplicity. Avoid clutter. Avoid gratuitous use visual attributes (color, size, shape) show attributes data. Avoid background colors. Use grid lines sparingly make interpretation data easier. readable. default sizes axis labels text rarely big enough. almost always need make bigger. Maximize data-ink ratio, within reason. Related point 3, “ink” figure show data rather non-data (axis ticks/labels, titles, legends, grid lines, etc.). Maximize ink shows data relative non-data, within reason. visual hierarchy. important information plot visible. Use layering, color, brightness, size, transparency, etc. make important attributes (generally data, sometimes even specific portions data) jump less important attributes (axis ticks/lines, grid lines, less important data points) fade background.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/graphics.html","id":"what-type-of-figure-should-i-use","dir":"Articles","previous_headings":"","what":"What type of figure should I use?","title":"Checklist and tips for publication-quality graphics in R","text":"Trends time series - line chart Amounts/comparisons discrete groups - bar chart, dot plot error bars Frequencies/distributions - histogram Associations 2 continuous variables - scatterplot Comparing distributions discrete groups - box--whisker plot, violin plt Spatial relationships - map","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/graphics.html","id":"visualization-checklist","dir":"Articles","previous_headings":"","what":"Visualization checklist","title":"Checklist and tips for publication-quality graphics in R","text":"list considerations making high-quality figures publications. complete list considered suggestions. figure include caption clearly explains elements needed interpret visualization? Remember caption figure understandable without referencing main text. figure accurately show variability data uncertainty estimates? axes start stop reasonable values? axis titles clearly indicate variables shown? include units? axis labels, axis titles, text annotations appropriately sized? figure includes different colors, shapes, sizes, attributes communicate properties data? figure includes different colors, shapes, sizes, legend show values represented attributes? color palettes colorblind-friendly? overlapping elements (points, bars, etc.), can clearly distinguished? figure includes multiple panels, axis limits consistent? figure includes multiple panels, panel labeled? grid lines? , show relevant information needed interpret figure? grid lines? , appropriately sized colored distract data? use 3D pie chart? 😠","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/graphics.html","id":"saving-high-resolution-figures-for-publication","dir":"Articles","previous_headings":"","what":"Saving high-resolution figures for publication","title":"Checklist and tips for publication-quality graphics in R","text":"many cases, need save figures rather render directly .rmd file. ggsave() function (opinion) easiest way save high-resolution figures. default, ggsave() save last plot created R using ssame size graphics device. tell function save figure name file. , example, following code save ggsave() also uses whatever file type name figure file guess format save figure (case, png). Options include: “eps”, “ps”, “tex”, “pdf”, “jpeg”, “tiff”, “png”, “bmp”, “svg”. can also change defaults , example, save specific figure object, change figure size, change figure resolution. example, Easy!","code":"libary(ggplot2)  df <- data.frame(x = seq(1:10),                   y = seq(1:10))  ggplot(df, aes(x = x, y = y)) +   geom_point()  ggsave(\"figs/scatterplot.png\") libary(ggplot2)  df <- data.frame(x = seq(1:10),                   y = seq(1:10))  p <- ggplot(df, aes(x = x, y = y)) +       geom_point()  ggsave(filename = \"figs/scatterplot.png\",        plot = p,        width = 5,         height = 8,        units = \"in\",        dpi = 600)"},{"path":"http://rushinglab.github.io/WILD8370/articles/graphics.html","id":"additional-resources","dir":"Articles","previous_headings":"","what":"Additional resources","title":"Checklist and tips for publication-quality graphics in R","text":"Fundamentals Data Visualization, Claus Wilke. comprehensive book data visualization, lots R code.","code":""},{"path":[]},{"path":"http://rushinglab.github.io/WILD8370/articles/homework.html","id":"step-1-create-a-new-directory-to-store-your-homework-files","dir":"Articles","previous_headings":"Homework steps","what":"Step 1: Create a new directory to store your homework files","title":"Homework instructions","text":"Create new directory (ideally subdirectoy WILD8370\\homework directory) call LastNameFirstName-Homework#, replacing LastNameFirstName last first names # appropriate homework number","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/homework.html","id":"step-2-create-a-new-r-markdown-file","dir":"Articles","previous_headings":"Homework steps","what":"Step 2: Create a new R Markdown file","title":"Homework instructions","text":"2a) Click File -> New File -> R Markdown... 2b) Title: window type Lab # assignment, substituting correct lab number. 2c) Author window, type name 2d) Click Ok 2e) Save R Markdown file LastnameFirstname-homework# directory created step 1, replacing LastNameFirstName last first names # appropriate homework number","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/homework.html","id":"step-3-complete-the-assignment","dir":"Articles","previous_headings":"Homework steps","what":"Step 3: Complete the assignment","title":"Homework instructions","text":"Complete assignment, following instructions lab document go","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/homework.html","id":"step-4-submit-your-assignment","dir":"Articles","previous_headings":"Homework steps","what":"Step 4: Submit your assignment","title":"Homework instructions","text":"4a) submitting assignment, always click “Knit” button sure .Rmd file can rendered HTML page. problems rendering file, please contact TA prior submission deadline. 4b) know file can rendered, upload LastnameFirstname-homework#.Rmd LastnameFirstname-homework#.html files eLC correct assignment folder Assignments fail follow instructions graded","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/homework.html","id":"notes","dir":"Articles","previous_headings":"Homework steps","what":"Notes:","title":"Homework instructions","text":"Homework graded complete/incomplete basis based effort. find homework difficult encounter error solve, write problem , ’ve tried, solutions didn’t work. Homework fully answered detailed explanation steps tried solve issue given full credit help us understand need focus future lectures.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"what-is-r","dir":"Articles","previous_headings":"","what":"What is R?","title":"Lab 0: Introduction to R","text":"R free, open-source programming language software environment statistical computing, bioinformatics, visualization general computing. based ever-expanding set analytical packages perform specific analytical, plotting, programming tasks.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"why-r","dir":"Articles","previous_headings":"","what":"Why R?","title":"Lab 0: Introduction to R","text":"R free(!), runs pretty much every operating system, huge user base. R far programming language working data, widely used language fields ecology, evolution, wildlife sciences. plan pursue career fields, proficiency Ris quickly becoming prerequisite many jobs. Even don’t pursue career one fields, ability manipulate, analyze, visualize data (otherwise known data science) extremely marketable skill many professions right now.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"additional-resources-and-where-to-get-help","dir":"Articles","previous_headings":"","what":"Additional resources and where to get help","title":"Lab 0: Introduction to R","text":"go basics using R lab sessions many good online resources learning R getting help. favorites (material developed) include: Tom Edward’s online Learning R course John Fieberg’s online Statistics Ecologists book Data Analysis Visualization R Ecologists course, encounter error messages don’t understand need help figuring accomplish something R, google best friend (even experienced R users use google daily basis). key finding answers google asking right questions. spend much time topic lab, please refer links advice formulating R-related questions: ask R help Seeking help Data Analysis Visualization R Ecologists","code":""},{"path":[]},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"the-rstudio-interface-and-panes","dir":"Articles","previous_headings":"Using R- the very basics","what":"The RStudio interface and panes","title":"Lab 0: Introduction to R","text":"Although users can work directly R, choose use RStudio IDE (Integrated Development Environment) R. use RStudio, must first R installed. opening RStudio, see 3 panes1. Console: console appear left side screen. can type code directly console (also known command line) executed immediately. console also output shown tasks executed R. Environment pane: environment pane appear top right screen. , can see objects created R well values objects R interprets (later). environment pane also includes tabs require use class. Plot pane: plot pane appear bottom right screen. might imagine, graphics displayed created R. pane also includes several useful tabs including Files tab (allows navigate manage files), Packages tab (can install manage additional R packages), Help tab can search R documentation pages.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"using-r-as-a-calculator","dir":"Articles","previous_headings":"Using R- the very basics","what":"Using R as a calculator","title":"Lab 0: Introduction to R","text":"statistical programming tool, one thing R good math. starting point, let’s treat R like fancy calculator. interact calculator typing numbers operators (+, -, *, /) Console window. Let’s try - bottom left window (Console), write Rcode required add two plus two press enter: run code, see answer printed window. Play code bit - try changing number operators run code .","code":"2+2"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"creating-objects","dir":"Articles","previous_headings":"Using R- the very basics","what":"Creating objects","title":"Lab 0: Introduction to R","text":"can run R like calculator typing equations directly console printing answer. usually don’t want just calculation see answer. Instead, assign values objects. object saved R’s memory allows us use object later analysis. might seem bit confusing new programming let’s try . following code creates object called x assigns value 3: operator <-2 3 assignments R. Whatever left <- object’s name whatever right value. see later, objects can much complex simply number now, ’ll keep simple. try - change code create object called new.x. Instead assigning new.x number, give calculation, example 25/5. think value new.x ?","code":"x <- 3"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"naming-objects","dir":"Articles","previous_headings":"Using R- the very basics","what":"Naming objects","title":"Lab 0: Introduction to R","text":"’s good idea give objects names tell something object represents. Names can long want spaces (also remember long names require typing brevity good rule thumb). Names can contain numbers letters begin number. R also case-sensitive , example, Apple apple. creating object names, also good idea avoid words show R functions. R generally smart enough distinguish attempting create object vs use function, avoiding practice save headache interpreting code (especially code looked ).","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"working-with-objects","dir":"Articles","previous_headings":"Using R- the very basics","what":"Working with objects","title":"Lab 0: Introduction to R","text":"exercise , may noticed running code, R print anything. simply told R create object (top right window, click Environment tab, see x new.x). Now stored R’s memory, can lot things . one, can print see value. , simply type name object run code4: can also use objects create new objects. think following code ? running , print new object y see value. right?","code":"new.x <- 25/5 new.x #> [1] 5 x <- 3 y <- x*4"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"r-scripts","dir":"Articles","previous_headings":"","what":"R scripts","title":"Lab 0: Introduction to R","text":"console useful simple tasks analyses become complicated, console efficient. need go back change line code? want show code someone else get help? Instead using console, work done using scripts (source editor pane). Scripts special files allow us write, save, run many lines code. Scripts can saved can work later send collaborators. create script, click File -> New File -> R Script. new file show new window.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"commenting-your-code","dir":"Articles","previous_headings":"R scripts","what":"Commenting your code","title":"Lab 0: Introduction to R","text":"R ignore code follows #. useful making code readable others. Use comments remind newly created object , explain line code , leave reminder later, etc. example, previous code, might good idea use comments define object represents: Notice run code, R ignores comments.","code":"n1 <- 44     # Number of individuals captured on first occasion  n2 <- 32     # Number of individuals captured on second occasion    m2 <- 15     # Number of previously marked individuals captured on second occasion"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"the-working-directory","dir":"Articles","previous_headings":"R scripts","what":"The working directory","title":"Lab 0: Introduction to R","text":"Now created new R script, need able save file somewhere computer. , can set working directory. addition providing place save script, setting working directory also tells R like put files come data management analyses (e.g. spreadsheets graphics) well find source data plan use particular project. two methods exist set working directory within R. can choose set working directory clicking Session –> Set working directory –> Choose directory navigating folder like store files. opened R script unsure current working directory located, can run getwd() see current working directory. can set working directory directly R script using setwd() function. example, set working directory folder called Lab_1 desktop, run following line code: C:/Users/mab46065/Desktop/Lab_1. Notice although computer probably create folder pathway using backslash (\\), R require forward slashes (/) instead. Also, using Mac, omit c: directory name.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"r-data-object-types","dir":"Articles","previous_headings":"","what":"R data object types","title":"Lab 0: Introduction to R","text":"point, briefly talked creating objects R. , discuss different object types R. important know types objects (e.g. vectors, lists, matrices, factors, data frames, arrays) working R interpret differently different object types required perform certain tasks. learn data structures encounter lab exercises.","code":""},{"path":[]},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"integer-class","dir":"Articles","previous_headings":"R data object types > Vectors","what":"Integer class","title":"Lab 0: Introduction to R","text":"far, working objects store single number. However, often convenient store string numbers single object. R, strings called vectors usually created enclosing string c( ): can also create sequences consecutive numbers different ways: seq() function flexible useful familiar , sure look help page better understand use . Another useful function creating vectors rep(), repeats values vector: : sure notice difference using times argument vs argument! function class() indicates class (type element) object:","code":"x <- c(3,5,2,5) x #> [1] 3 5 2 5 x <- 1:10 x #>  [1]  1  2  3  4  5  6  7  8  9 10  x2 <- seq(from = 1, to = 10, by = 1) x2 #>  [1]  1  2  3  4  5  6  7  8  9 10 rep(x2, times = 2) #>  [1]  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10 rep(x2, each = 2) #>  [1]  1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10 class(x) #> [1] \"integer\""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"character-class","dir":"Articles","previous_headings":"R data object types > Vectors","what":"Character class","title":"Lab 0: Introduction to R","text":"vector can also contain characters (though mix numbers characters vector!): quotes around “Occasion1”, “Occasion2”, “Occasion3” critical. Without quotes, R assume objects called Occasion1, Occasion2 Occasion3. objects don’t exist R’s memory, error message. Vectors can length (including 1. fact, numeric objects ’ve working just vectors length 1). function length() tells long vector : class vector numeric characters entries? Hint: can also use c() function add elements vector:","code":"occasions <- c(\"Occasion1\", \"Occasion2\", \"Occasion3\") occasions #> [1] \"Occasion1\" \"Occasion2\" \"Occasion3\" class(occasions) #> [1] \"character\" length(x) #> [1] 10 mixed <- c(1, 2, \"3\", \"4\") y <- c(x, 4,8,3)"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"factor-class","dir":"Articles","previous_headings":"R data object types > Vectors","what":"Factor class","title":"Lab 0: Introduction to R","text":"Another class vectors referred factors. Factors similar character vectors R interpreting text strings perform math . difference, however, R sees factors grouping variables. category within factor referred ‘level’5.","code":"Species <- as.factor(c(1,3,4,2,3,3,4,1,1,1)) Species #>  [1] 1 3 4 2 3 3 4 1 1 1 #> Levels: 1 2 3 4 class(Species) #> [1] \"factor\""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"vectorized-arithmetic","dir":"Articles","previous_headings":"R data object types > Vectors","what":"Vectorized arithmetic","title":"Lab 0: Introduction to R","text":"One useful properties vectors R can use simplify basic arithmetic operations need done multiple observations. example, consider following data wing chord (measure wing length) body mass Swainson’s thrushes (Catharus ustulatus): Swainson’s Thrush. Image courtesy VJAnderson via Wikicommons Perhaps want derive body condition individual based measures. One common metric body condition used ornithologists masssize\\frac{mass}{size}, wing chord used proxy body size. calculate body condition individual: time consuming error prone. Luckily, R vectorize basic arithmetic: can see, divide one vector another, R divides first element first vector first element second vector, etc. returns vector. Vectorized arithmetic works well vectors using length. happen though perform arithmetic vectors different lengths? Try running following code seeing R vectors. Notice way R recycles vector depends longer.","code":"cond1 <- 36.2/95.1 # Body condition of the first individual  cond2 <- 34.6/88.4 # Body condition of the second individual mass <- c(36.2, 34.6, 31.0, 31.8, 29.4, 32.0) wing <- c(95.1, 88.4, 97.9, 96.8, 92.3, 90.6)  cond <- mass/wing cond #> [1] 0.3807 0.3914 0.3166 0.3285 0.3185 0.3532 a <- c(1,10,100,1000) b <- c(1,2,3,4,5) c <- a/b c #> [1]   1.00   5.00  33.33 250.00   0.20  x <- c(1,10,100,1000, 10000) y <- c(1,2,3,4) z <- x/y z #> [1]     1.00     5.00    33.33   250.00 10000.00"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"indexing-vectors","dir":"Articles","previous_headings":"R data object types > Vectors","what":"Indexing vectors","title":"Lab 0: Introduction to R","text":"Often need work just subset vector. example, maybe vector plant biomass measured along transects need first third observations. Notice index certain elements vector y, use square brackets. Inside brackets, provided integer vector, integer refers position elements first vector. indexing vector can length (including 1). can also index vectors using logical vector. logical vector special type object contains values TRUE FALSE. using logical vector indexing, logical vector indicates elements keep (TRUE) remove (FALSE) original vector. reason, indexing vector must length focal vector; .e., length() == length(v) can also use indexing remove elements vector: rearrange order vector","code":"y <- c(2, 4, 8, 4, 25) y[c(1,3)] #> [1] 2 8 # Logical vector (which elements of y are greater than 4?) y > 4 #> [1] FALSE FALSE  TRUE FALSE  TRUE # Indexing using a logical vector (keep elements 3 and 5) y[y > 4] #> [1]  8 25 # Remove the second element y[-2] #> [1]  2  8  4 25 y[c(5,4,3,2,1)] #> [1] 25  4  8  4  2"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"functions","dir":"Articles","previous_headings":"R data object types","what":"Functions","title":"Lab 0: Introduction to R","text":"power R apparent large number built-functions available users. Functions small bits code perform specific task. functions accept one inputs called arguments return value new object. Let’s say following data number ticks recorded 5 dogs: total number ticks recorded study? , can use built-sum() function: mean number ticks per dog? variance?","code":"ticks <- c(4,7,2,3,150)  sum(ticks) #> [1] 166 mean(ticks) #> [1] 33.2 var(ticks) #> [1] 4267"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"arguments","dir":"Articles","previous_headings":"R data object types > Functions","what":"Arguments","title":"Lab 0: Introduction to R","text":"Every function takes different set arguments many cases need look arguments . best way get help specific function type question mark followed function name, bring help page bottom right panel. example, round function rounds number specified number decimal places. useful function don’t want print really large number digits: see round takes argument called x, number want round, number digits want round . provide arguments exact order defined don’t name . example, : name arguments, can switch order: Although don’t name arguments, ’s good idea get habit naming . make code easier read, help avoid mistakes can occur don’t put arguments correct order, makes easier trouble shoot code doesn’t expect .","code":"?round y <- mean(ticks) y #> [1] 33.2  round(y, 0) #> [1] 33 round(digits = 0, x = y) #> [1] 33"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"matrices","dir":"Articles","previous_headings":"R data object types","what":"Matrices","title":"Lab 0: Introduction to R","text":"Matrices similar vectors two dimensions. first dimension shows number rows matrix second shows number columns. , combined multiple vectors create matrix. Notice vectors need length. Notice matrices can contain one data class, numeric vectors coerced characters. matrices many uses R, one drawback lead us directly next object type.","code":"Site <- c(1,2,3,4,5) Species <- c('Alasmidonta varicosa',              'Alasmidonta varicosa',              'Alasmidonta varicosa',               'Lasmigona decorata',               'Lasmigona decorata') Year <- c(rep(2023,5)) mymatrix <- cbind(Site, Species, Year) mymatrix #>      Site Species                Year   #> [1,] \"1\"  \"Alasmidonta varicosa\" \"2023\" #> [2,] \"2\"  \"Alasmidonta varicosa\" \"2023\" #> [3,] \"3\"  \"Alasmidonta varicosa\" \"2023\" #> [4,] \"4\"  \"Lasmigona decorata\"   \"2023\" #> [5,] \"5\"  \"Lasmigona decorata\"   \"2023\""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"data-frames","dir":"Articles","previous_headings":"R data object types","what":"Data frames","title":"Lab 0: Introduction to R","text":"Although useful many applications, vectors matrices limited ability store multiple types data (numeric character). data frames become useful. Perhaps common type data object use R data frame. Data frames tabular objects (rows columns) similar structure spreadsheets (think Excel GoogleSheets). effect, data frames store multiple vectors - column data frame vector. advantage matrices column can different class (numeric, character, etc.) values within column must class. Just first row Excel spreadsheet can list column names, column data frame name (hopefully) provides information values column represent. see data frames work, let’s load data frame called jayData comes FANR6750 package.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"an-aside-about-packages","dir":"Articles","previous_headings":"R data object types > Data frames","what":"An aside about packages","title":"Lab 0: Introduction to R","text":"One R’s primary strengths large number packages available users. Packages units shareable code data created R users. already seen built-functions R comes . Packages allow users share lots lots functions serve specific purposes. Packages also allow users share data sets. packages cleaning data, visualizing data, making maps, fitting specialized models, basically anything else can think . Accessing code package first requires installing package. needs done per computer usually done using install.packages() function: Note name package (case devtools) must quotation marks. Packages installed using install.packages() stored centralized repository called CRAN (Comprehensive R Archive Network). devtools (package) installed computer, need re-run install.packages() function unless re-install/update R need update package newer version. Installing package automatically make functions package available given R session. tell R functions come , must load package using library() function6: Unlike install.packages(), library() must re-run time open R. people include calls library() beginning script packages needed run code loaded beginning script. Occasionally, packages stored places (e.g., github). packages can installed using different functions. example, created package course contains small data sets use labs throughout semester. package stored github can installed running: Note install_github() function devtools package need run library(devtools) install package. Make sure install FANR6750 package now access data sets.","code":"install.packages(\"devtools\") library(devtools) install_github(\"RushingLab/WILD8370\")"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"back-to-dataframes","dir":"Articles","previous_headings":"R data object types > Data frames","what":"Back to dataframes","title":"Lab 0: Introduction to R","text":"Note - discussed , want access function data sets come packages, first need load package current working environment. , use library() function, unquoted package name argument. loaded, package’s functions available use. Alternatively, can access functions given package without loading package using package.name::function.name(). example, want use filter() function dplyr package, type dplyr::filter(). Although less commonly used, method advantages: Sometimes different packages functions names. R default using function package loaded last. example, raster package also function called filter() load dplyr first (using library()raster, R default using raster’s filter() function, cause problems. share code others, :: method makes clear packages use functions. additional clarity often helpful reason often use :: course. get quick idea information data frame contains, can use head() tail() functions, print first last 6 rows data frame: can see jaydata contains eight columns: x, y, elevation, forest, chaparral, habitat, seeds, jays. ’ll learn columns represents later semester, though just like functions, many data sets help pages also can access help pages using ?jaydata. Several useful functions investigating structure data frames str() summary() str() tells us structure data frame, example x y numeric columns habitat contains character strings. summary() provides simple summary statistics variable. Another useful function nrow(), tells us now many rows data frame (similar length() vectors):","code":"library(WILD8370) data(\"jaydata\") # the data() function loads data sets the come with packages  head(jaydata) #>        x       y elevation forest chaparral habitat seeds jays #> 1 258637 3764124       423   0.00      0.02     Oak   Med   34 #> 2 261937 3769224       506   0.10      0.45     Oak   Med   38 #> 3 246337 3764124       859   0.00      0.26     Oak  High   40 #> 4 239437 3763524      1508   0.02      0.03    Pine   Med   43 #> 5 239437 3767724       483   0.26      0.37     Oak   Med   36 #> 6 236437 3769524       830   0.00      0.01     Oak   Low   39  tail(jaydata) #>          x       y elevation forest chaparral habitat seeds jays #> 95  258937 3767124       804   0.19      0.68     Oak   Med   40 #> 96  259837 3768024       210   0.00      0.00     Oak   Low   33 #> 97  249337 3769524       467   0.70      0.09    Pine   Med   36 #> 98  262237 3767424      1318   0.02      0.23     Oak   Med   44 #> 99  261937 3770124       354   0.00      0.05    Bare   Low   33 #> 100 247837 3769524       686   0.10      0.32     Oak   Med   40 str(jaydata) #> 'data.frame':    100 obs. of  8 variables: #>  $ x        : num  258637 261937 246337 239437 239437 ... #>  $ y        : num  3764124 3769224 3764124 3763524 3767724 ... #>  $ elevation: int  423 506 859 1508 483 830 457 304 834 164 ... #>  $ forest   : num  0 0.1 0 0.02 0.26 0 0.02 0 0.54 0 ... #>  $ chaparral: num  0.02 0.45 0.26 0.03 0.37 0.01 0.22 0.09 0.21 0.11 ... #>  $ habitat  : chr  \"Oak\" \"Oak\" \"Oak\" \"Pine\" ... #>  $ seeds    : chr  \"Med\" \"Med\" \"High\" \"Med\" ... #>  $ jays     : int  34 38 40 43 36 39 38 35 41 33 ...  summary(jaydata) #>        x                y             elevation        forest       #>  Min.   :230737   Min.   :3761424   Min.   :  12   Min.   :0.0000   #>  1st Qu.:238762   1st Qu.:3765324   1st Qu.: 365   1st Qu.:0.0000   #>  Median :245587   Median :3766824   Median : 548   Median :0.0000   #>  Mean   :246949   Mean   :3767130   Mean   : 659   Mean   :0.0553   #>  3rd Qu.:254662   3rd Qu.:3768699   3rd Qu.: 929   3rd Qu.:0.0300   #>  Max.   :266137   Max.   :3773724   Max.   :1537   Max.   :0.7000   #>    chaparral       habitat             seeds                jays      #>  Min.   :0.000   Length:100         Length:100         Min.   :30.0   #>  1st Qu.:0.080   Class :character   Class :character   1st Qu.:36.0   #>  Median :0.210   Mode  :character   Mode  :character   Median :38.0   #>  Mean   :0.241                                         Mean   :38.6   #>  3rd Qu.:0.370                                         3rd Qu.:41.0   #>  Max.   :0.850                                         Max.   :48.0 nrow(jaydata) #> [1] 100"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"subsetting-data-frames","dir":"Articles","previous_headings":"R data object types > Data frames","what":"Subsetting data frames","title":"Lab 0: Introduction to R","text":"see shortly, one common tasks working data frames creating new objects parts full data frame. task involves subsetting data frame - selecting specific rows columns. many ways subsetting data frames R, many discuss learn .","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"selecting-columns","dir":"Articles","previous_headings":"R data object types > Data frames > Subsetting data frames","what":"Selecting columns","title":"Lab 0: Introduction to R","text":"First, may want select subset columns big data frame. Data frames essentially tables, means can reference rows columns number: data.frame[row#, column#]. row column numbers put inside square brackets following name data frame object. row number always comes first column number second. want select rows specific column, just leave row# blank. example, wanted vector containing number jays survey location: can also select columns using data.frame$column (data.frame name data frame object column name column). example, Notice hit tab type $, RStudio bring columns can use buttons find one want. Sometimes may want select one column. One way indexing using column names7: can also use select remove columns:","code":"jaydata[,8] #>   [1] 34 38 40 43 36 39 38 35 41 33 34 37 37 38 42 43 39 37 38 40 37 35 37 44 45 #>  [26] 37 36 34 48 43 39 41 45 38 35 38 39 38 41 38 36 43 38 36 33 41 38 30 39 36 #>  [51] 39 36 34 30 38 37 44 36 36 40 44 48 37 41 42 30 41 39 43 30 42 42 41 38 36 #>  [76] 37 33 44 38 35 45 41 35 38 37 45 33 42 34 45 40 42 40 44 40 33 36 44 33 40 jaydata$jays #>   [1] 34 38 40 43 36 39 38 35 41 33 34 37 37 38 42 43 39 37 38 40 37 35 37 44 45 #>  [26] 37 36 34 48 43 39 41 45 38 35 38 39 38 41 38 36 43 38 36 33 41 38 30 39 36 #>  [51] 39 36 34 30 38 37 44 36 36 40 44 48 37 41 42 30 41 39 43 30 42 42 41 38 36 #>  [76] 37 33 44 38 35 45 41 35 38 37 45 33 42 34 45 40 42 40 44 40 33 36 44 33 40 head(jaydata[, c('x', 'y', 'jays')]) #>        x       y jays #> 1 258637 3764124   34 #> 2 261937 3769224   38 #> 3 246337 3764124   40 #> 4 239437 3763524   43 #> 5 239437 3767724   36 #> 6 236437 3769524   39 head(subset(jaydata, select= -c(seeds))) #>        x       y elevation forest chaparral habitat jays #> 1 258637 3764124       423   0.00      0.02     Oak   34 #> 2 261937 3769224       506   0.10      0.45     Oak   38 #> 3 246337 3764124       859   0.00      0.26     Oak   40 #> 4 239437 3763524      1508   0.02      0.03    Pine   43 #> 5 239437 3767724       483   0.26      0.37     Oak   36 #> 6 236437 3769524       830   0.00      0.01     Oak   39"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab01_intro_to_R.html","id":"filtering-rows","dir":"Articles","previous_headings":"R data object types > Data frames > Subsetting data frames","what":"Filtering rows","title":"Lab 0: Introduction to R","text":"select specific rows, can use row# method learned , time leaving columns blank: want one row, just put vector rows want: Note can use square brackets also subset vectors, case don’t need comma long tell R column want first: Sometimes, may know specific row number(s) want know value one columns want keep. can R indexing using logical subsetting. example, want just surveys conducted oak habitat, use: Notice need two equals signs (==) telling R want row habitat equals Oak. also select multiple rows using operators like greater , less , etc. slightly complicated example:","code":"jaydata[1,] #>        x       y elevation forest chaparral habitat seeds jays #> 1 258637 3764124       423      0      0.02     Oak   Med   34 jaydata[1:2,] #>        x       y elevation forest chaparral habitat seeds jays #> 1 258637 3764124       423    0.0      0.02     Oak   Med   34 #> 2 261937 3769224       506    0.1      0.45     Oak   Med   38  jaydata[c(1,30),] #>         x       y elevation forest chaparral habitat seeds jays #> 1  258637 3764124       423      0      0.02     Oak   Med   34 #> 30 259537 3765924      1419      0      0.07    Pine   Med   43 jaydata$jays[1] #> [1] 34 head(jaydata[jaydata$habitat == \"Oak\",]) #>        x       y elevation forest chaparral habitat seeds jays #> 1 258637 3764124       423   0.00      0.02     Oak   Med   34 #> 2 261937 3769224       506   0.10      0.45     Oak   Med   38 #> 3 246337 3764124       859   0.00      0.26     Oak  High   40 #> 5 239437 3767724       483   0.26      0.37     Oak   Med   36 #> 6 236437 3769524       830   0.00      0.01     Oak   Low   39 #> 7 263737 3766524       457   0.02      0.22     Oak   Med   38 head(jaydata[jaydata$elevation > 1000,]) #>         x       y elevation forest chaparral habitat seeds jays #> 4  239437 3763524      1508   0.02      0.03    Pine   Med   43 #> 24 261637 3768324      1276   0.02      0.36     Oak  High   44 #> 25 248737 3766524      1024   0.03      0.41    Pine   Low   45 #> 29 255937 3765024      1400   0.02      0.45     Oak  High   48 #> 30 259537 3765924      1419   0.00      0.07    Pine   Med   43 #> 32 245737 3762924      1004   0.02      0.32     Oak   Low   41 head(jaydata[jaydata$elevation < 1000 & jaydata$habitat == \"Oak\",]) #>        x       y elevation forest chaparral habitat seeds jays #> 1 258637 3764124       423   0.00      0.02     Oak   Med   34 #> 2 261937 3769224       506   0.10      0.45     Oak   Med   38 #> 3 246337 3764124       859   0.00      0.26     Oak  High   40 #> 5 239437 3767724       483   0.26      0.37     Oak   Med   36 #> 6 236437 3769524       830   0.00      0.01     Oak   Low   39 #> 7 263737 3766524       457   0.02      0.22     Oak   Med   38"},{"path":"http://rushinglab.github.io/WILD8370/articles/lab02.html","id":"analysis-flowchart","dir":"Articles","previous_headings":"","what":"Analysis Flowchart","title":"lab01b","text":"One hardest part Bayesian analysis converting idea ecological system English math math English. Unlike lot maximum likelihood packages, get decide exact variable model defined, distributions think parameters come , assumptions making underlying system trying understand. process made confusing fact aren’t directly math ! can think process fun little flow chart:  Steps 1 -3 specific Bayesian analysis – need thing maximum likelihood analysis well. Notice steps 4 5 simply Bayesian analysis class. need MCMC software R perform Bayesian analysis, just happens easiest way . today, ’ll focus going steps 2a 3.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"http://rushinglab.github.io/WILD8370/articles/moment_matching.html","id":"moments","dir":"Articles","previous_headings":"Beta distribution","what":"Moments","title":"Probability distribution cheatsheet","text":"$$\\Large \\mu = \\frac{\\alpha}{\\alpha + \\beta}$$ $$\\Large \\sigma^2 = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}$$","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/moment_matching.html","id":"moment-matching","dir":"Articles","previous_headings":"Beta distribution","what":"Moment matching","title":"Probability distribution cheatsheet","text":"$$\\Large \\alpha = \\bigg(\\frac{1-\\mu}{\\sigma^2}- \\frac{1}{\\mu} \\bigg)\\mu^2$$ $$\\Large \\beta = \\alpha \\bigg(\\frac{1}{\\mu}-1\\bigg)$$ ## Gamma distribution","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/moment_matching.html","id":"moments-1","dir":"Articles","previous_headings":"Beta distribution","what":"Moments","title":"Probability distribution cheatsheet","text":"$$\\Large \\mu = \\frac{\\alpha}{\\beta}$$ $$\\Large \\sigma^2 = \\frac{\\alpha}{\\beta^2}$$","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/moment_matching.html","id":"moment-matching-1","dir":"Articles","previous_headings":"Beta distribution","what":"Moment matching","title":"Probability distribution cheatsheet","text":"$$\\Large \\alpha = \\frac{\\mu^2}{\\sigma^2}$$ $$\\Large \\beta =  \\frac{\\mu}{\\sigma^2}$$","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/priors.html","id":"question-and-model-development","dir":"Articles","previous_headings":"","what":"Question and model development","title":"Lab5: Priors","text":"One issue many ecological studies logistically financially difficult collect data large number individuals. result, vital rate estimates often based relatively small sample sizes, can lead high uncertainty possibly spurious results. precisely instances Bayesian methods can shine - saw lecture, ability incorporate previous knowledge parameter values via informative priors equivalent increasing sample size. explore different ways generating informative priors, borrow data clever ideas recently published paper dynamics Polar Bear (Ursus maritimus) populations Chukchi Sea (Regehr et al. 2018). example, focus subset full model, namely estimating annual survival adult female bears. model developed Regehr et al. (2018), female survival identifiable estimates imprecise using available data due small sample sizes. result, authors chose develop informative priors based published survival estimates populations. case, authors fortunate handful previous studies lean-later exercise learn developed priors studies. first, let’s assume published studies still want benefits informative priors.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/priors.html","id":"example-1-domain-expertise","dir":"Articles","previous_headings":"","what":"Example 1: Domain expertise","title":"Lab5: Priors","text":"Even previous estimates polar bear survival, completely ignorant survival species. can use domain expertise develop prior improves upon non-informative option. Polar bears large, long-lived carnivore life expectancy 20-25 years (Ramsay & Stirling 1988). simple fact suggests adult survival must pretty high - even annual survival probability 95%95\\%, individual 36% probability surviving 20 years. survival probabilities much less ∼90%\\sim 90\\% pretty surprising pretty suspicious estimates less ∼80%\\sim 80\\% (imply 1%1\\% female polar bears make 20 years age). course, polar bear populations many areas declining pretty quickly, suggesting maybe adult survival rates lower historical levels. although can pretty survival high (e.g., >80%>80\\%), ’re super confident actual survival rate. regards prior, suggests want prior puts weight >80%>80\\% wide enough reflect uncertainty actual survival rates.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/priors.html","id":"turning-our-expertise-into-a-prior","dir":"Articles","previous_headings":"Example 1: Domain expertise","what":"Turning our expertise into a prior","title":"Lab5: Priors","text":"modeling continuous random variable must 0 1 (.e., probability), beta distribution natural choice. shape beta distribution governed two parameters, α\\alpha β\\beta  learned lecture turn mean variance random variable parameters probability distribution using moment matching. beta distribution: α=(1−μσ2−1μ)μ2\\alpha = \\bigg(\\frac{1-\\mu}{\\sigma^2}- \\frac{1}{\\mu} \\bigg)\\mu^2 \\tag{1}β=α(1μ−1)\\beta = \\alpha \\bigg(\\frac{1}{\\mu}-1\\bigg) \\tag{2} Given domain expertise, reasonable choice mean variance prior might μ=0.9\\mu=0.9 σ2=0.005\\sigma^2=0.005 (may seem like small variance ’ll see , actually produces relatively diffuse prior. Figuring appropriate variance probabilities easy best option usually play values explore properties resulting distribution make sure seems reasonable). Plugging values equations 1 2 gives: α=(1−0.90.005−10.9)0.92=15.3\\alpha = \\bigg(\\frac{1-0.9}{0.005}- \\frac{1}{0.9} \\bigg)0.9^2 = 15.3β=3.6(10.9−1)=1.7\\beta = 3.6 \\bigg(\\frac{1}{0.9}-1\\bigg) = 1.7 always, visualize distribution make sure matches think look like:  seems reasonable given understanding species biology. However, essentially made variance term give relatively diffuse prior, likely careful justified choice probably need include formal prior sensitivity analyses.","code":"## Target mean and variance mu <- 0.9 var <- 0.005  ## Beta parameters alpha <- mu^2 * ((1-mu)/var - (1/mu)) beta <- alpha * (1/mu - 1)  ## Range of possible survival probabilities phi <- seq(0, 1, by = 0.001)   beta_df <- data.frame(phi = phi,                       density = dbeta(phi, alpha, beta),                       Approach = \"Domain expertise\")  ggplot(beta_df, aes(x = phi, y = density, color = Approach)) +    geom_path() +   scale_x_continuous(expression(phi), limits = c(0.5, 1))"},{"path":"http://rushinglab.github.io/WILD8370/articles/priors.html","id":"example-2-published-studies","dir":"Articles","previous_headings":"","what":"Example 2: Published studies","title":"Lab5: Priors","text":"Polar bears relatively well-studied surprised find least published estimates adult female survival. turns , . Estimates studies included small data frame WILD8370 package: Rather rely solely domain expertise better option convert published estimates prior distribution. many ways done. explore several.","code":"data(\"SurvPriorData\")"},{"path":"http://rushinglab.github.io/WILD8370/articles/priors.html","id":"approach-1-mean-and-variance-of-published-estimates","dir":"Articles","previous_headings":"Example 2: Published studies","what":"Approach 1: Mean and variance of published estimates","title":"Lab5: Priors","text":"One reasonable way turn 6 published estimates single prior take mean variance 6 estimates use moment matching convert single beta distribution. Looks like domain knowledge wasn’t far ! Now can covert estimates α\\alpha β\\beta parameters :  can see, even though means two priors different, variance much smaller prior based published estimates, resulting much informative prior (prior suggests ’re much sure plausible values ϕ\\phi).","code":"(mu2 <- mean(SurvPriorData$phi)) #> [1] 0.935 (var2 <- sd(SurvPriorData$phi) ^ 2) #> [1] 0.00027 ## Beta parameters alpha2 <- mu2^2 * ((1-mu2)/var2 - (1/mu2)) beta2 <- alpha2 * (1/mu2 - 1)  beta_df2 <- data.frame(phi = phi,                       density = dbeta(phi, alpha2, beta2),                       Approach = \"Published means\")  beta_df <- dplyr::bind_rows(beta_df, beta_df2)  ggplot(beta_df, aes(x = phi, y = density, color = Approach)) + geom_path() +   scale_x_continuous(expression(phi), limits = c(0.5, 1))"},{"path":"http://rushinglab.github.io/WILD8370/articles/priors.html","id":"approach-2-mean-and-variance-of-published-estimates","dir":"Articles","previous_headings":"Example 2: Published studies","what":"Approach 2: Mean and variance of published estimates","title":"Lab5: Priors","text":"One reasons informative prior based published survival estimates narrow ignores study-specific uncertainties associated survival estimate. One argue ignoring source uncertainty leads prior confident possible values ϕ\\phi. However, incorporating study-specific uncertainty straightforward. One clever approach convert estimates study separate beta distributions, simulate survival estimates distribution, estimate “hyper-parameters” simulations together1. Understanding approach works best done example. Let’s start using moment matching estimate α\\alpha β\\beta parameters associated individual study. , ’ll take advantage way R performs operations vectors can just plug columns data frame directly formulas: Next, simulate bunch survival estimates distribution. easiest way create empty matrix hold values loop study simulate survival probabilities: Now hopefully can see approach clever. now 30000 plausible values adult female survival probability consistent published studies reflect multiple sources uncertainty vital rate2. simulated values, can now estimate “hyper-parameters” single beta distribution serve prior. First, estimate mean variance simulated values: can see variance samples much larger approach 1, reflecting additional source uncertainty approach 2. Now use moment matching code generate visualize prior:","code":"(alpha3 <- SurvPriorData$phi^2 * ((1-SurvPriorData$phi)/SurvPriorData$se^2 - (1/SurvPriorData$phi))) #> [1] 111.86  41.40  27.25 131.60 131.60  81.90 (beta3 <- alpha3 * (1/SurvPriorData$phi - 1)) #> [1] 5.887 3.600 1.434 8.400 8.400 8.100 ## Number of simulated values from each distribution. nSims <- 5000  ## Empty matrix to store the simulated survival probabilities sim_phi <- matrix(NA, nrow = nSims, ncol = dim(SurvPriorData)[1])  for(j in 1:dim(SurvPriorData)[1]){  sim_phi[,j] <- rbeta(n = nSims, alpha3[j], beta3[j]) } (mu3 <- mean(sim_phi)) #> [1] 0.9352 (var3 <- sd(sim_phi) ^ 2) #> [1] 0.001093 ## Beta parameters alpha4 <- mu3^2 * ((1-mu3)/var3 - (1/mu3)) beta4 <- alpha4 * (1/mu3 - 1)  beta_df3 <- data.frame(phi = phi,                       density = dbeta(phi, alpha4, beta4),                       Approach = \"Simulated\")  beta_df <- dplyr::bind_rows(beta_df, beta_df3)  sim_df <- data.frame(x = c(sim_phi))  ggplot() +    geom_histogram(data = sim_df, aes(x, stat(density)), alpha = 0.4,                  color = \"grey50\",                  fill =  WILD6900_colors$value[WILD6900_colors$name == \"success\"],                   binwidth = 0.005) +   geom_path(data = beta_df, aes(x = phi, y = density, color = Approach)) +   scale_x_continuous(expression(phi), limits = c(0.7, 1))"},{"path":"http://rushinglab.github.io/WILD8370/articles/priors.html","id":"questions-to-consider3","dir":"Articles","previous_headings":"","what":"Questions to consider3","title":"Lab5: Priors","text":"Informative vs vague: one hand, want posteriors reflect (affected ) prior knowledge. hand, collect data basically know answer? assess ‘sensitivity prior’: Ideally, test sensitive inferences choice prior distribution. quantified change posterior mean, standard deviation, etc? posterior unaffected prior, go trouble using informative priors? Process vs sampling noise: studies used create priors reflect range conditions population trajectories. approach 1, assume point estimates survival reflect process noise across populations. approach 2, use uncertainty study capture sampling process uncertainty. sources uncertainty care developing prior? Domain expertise: Incorporating sampling uncertainty may increased prior weight survival values conflict domain expertise (example, values much lower think plausible). However, values consistent possible survival values published studies. treat priors boundary statistical domain expertise?","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/priors.html","id":"prior-predictive-checks","dir":"Articles","previous_headings":"","what":"Prior Predictive Checks","title":"Lab5: Priors","text":"One issue priors can unexpected things undergo transformations. means prior might look diffuse can accidentally informative model written. See https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13407 great paper . instance, let’s say polar bear survival ϕ\\phi function age individual, cubs much lower survival adults: logit(ϕi)=β0+β1*ageilogit(\\phi_i) = \\beta_0 + \\beta_1*age_i might tempted use something simple like uniform β\\beta terms: β0∼Uniform(−5,5)\\beta_0 \\sim Uniform(-5, 5) However, imply ϕ\\phi? instance, β1\\beta_1 0 data, ϕ\\phi looks like:  Uh-oh! Nimble, can run model without data monitor latent variables double check priors expect. called Prior Predictive Check useful tool.","code":"beta0 <- runif(10000, -5, 5) par(mfrow = c(1,2)) hist(beta0, main = \"Prior\") hist(plogis(beta0), main = \"Posterior\", xlab = 'Survival')"},{"path":"http://rushinglab.github.io/WILD8370/articles/priors.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Lab5: Priors","text":"Ramsay, M.. Stirling, ., 1988. Reproductive biology ecology female polar bears (Ursus maritimus). Journal Zoology, 214(4), pp.601-633. Regehr, E.V., Hostetter, N.J., Wilson, R.R., Rode, K.D., Martin, M.S. Converse, S.J., 2018. Integrated population modeling provides first empirical estimates vital rates abundance polar bears Chukchi Sea. Scientific reports, 8(1), p.16780.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/priors.html","id":"homework-questions","dir":"Articles","previous_headings":"","what":"Homework Questions:","title":"Lab5: Priors","text":"studying population gopher tortoises, don’t lot data survival. want model juvenile adult survival : (ϕi=β0[agei])(\\phi_i = \\beta_0[age_i]). comb literature find following information. Using information, choose prior β0\\beta_0. Defend choice prior. (Note: can choose model β0\\beta_0 random fixed effect, sure defend choice.) study sites, apparent survival immature tortoises significantly lower adult tortoises, averaging 82.4 ± 3.8% Conecuh 69.7 ± 9.1% Green Grove (Tuberville et al 2014) Additionally, annual survivorship immature tortoises (73.8%, 95% CI = 56.3–86.1%) significantly lower adults (93.4%, 95% CI = 88.6–96.9%) (Howell et al 2019) Quarterly apparent survival differ significantly size classes, although point estimates lower small tortoises (91.6% ± 3.5, 95% CI: 81.6%–96.4%; n = 19) large tortoises (96.4% ± 2.5, 95% CI: 86.8%–99.1%; n = 13) (Stemle et. al 2024) Apparent annual survival adult tortoises averaged 0.98 ± 0.01 years excluding first two (Fig. 4). […] Survival immature tortoises lower adults averaged 0.84 ± 0.05 across years. (Tuberville et al 2008) 2021 Species Status Assessment (SSA) gopher tortoises used informed priors juvenile adult survival model population viability across Southeast USA. juvenile tortoises, used beta distribution mean 0.75 standard deviation 0.06. adult tortoises, used beta mean 0.96 standard deviation 0.03. Write two beta distributions used math form. Visually compare distributions prior chose Question 1. Imagine intercept-occupancy model logit(ψ)=αlogit(\\psi) = \\alpha. want put uninformative prior α\\alpha aren’t sure happen goes logit transformation. Use R simulate following priors 5000 times, graph prior resulting posterior ψ\\psi ggplot. ones, , seem reasonably uninformative? α∼Normal(0,10)\\alpha \\sim Normal(0, 10) α∼Gamma(10,10)\\alpha \\sim Gamma(10, 10) (shape, rate parameterization) α∼Beta(.3,.3)\\alpha \\sim Beta(.3, .3) α∼Exp(1)\\alpha \\sim Exp(1) α∼Cauchy(0,1)\\alpha \\sim Cauchy(0, 1) (location, scale) 1-10 scale, 1 worst week ever 10 best, rate week’s content? lingering questions/confusion lecture lab still ?","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/projects_and_directories.html","id":"common-workflows-and-their-problems","dir":"Articles","previous_headings":"","what":"Common workflows and their problems","title":"Improving your workflow through projects","text":"common workflow used many novice R users goes something like : Open base R maybe RStudio Create script save analysis_for_my_project.R Start script : Create bunch objects stuff : Realize need working dissertation instead side project open another script started earlier Get confused objects current environment created script rm(list = ls()) start scratch Rinse repeat","code":"rm(list = ls()) setwd(\"C:\\Users\\crushing\\path\\that\\only\\I\\have\")  library(package1) library(package2) x <- 1:10 y <- \"blah\""},{"path":"http://rushinglab.github.io/WILD8370/articles/projects_and_directories.html","id":"whats-wrong-with-this","dir":"Articles","previous_headings":"Common workflows and their problems","what":"What’s wrong with this?","title":"Improving your workflow through projects","text":"Remember open R (RStudio), create global workspace. objects create get stored. type ls() can see everything currently stored workspace. working different analyses global environment, easy accidentally create different objects name, write code depends code happens run previously one R session (example, loaded needed package one script didn’t add library(package) next script. happens try run code next time? often called “hidden dependency” can make life pretty miserable), many confusing behaviors. workflow also makes difficult share work. Remember R default looking /saving current working directory. control behavior, people taught use setwd(). problem path set using setwd() almost certainty specific computer used write code. use different computer later send code adviser help, able run without changing working directory. move files new place computer, code break. Got new computer? Oops, none code work anymore. running multiple analyses R session, ’ll also constantly change working directory, eventually lead confusion problems rerunning code. Manually setting working directory seems like minor annoyance constantly (example, instructor grade bunch homework assignments), minor annoyances add big headache. good news , ’s easy solution make life much easier.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/projects_and_directories.html","id":"rstudio-projects","dir":"Articles","previous_headings":"","what":"RStudio Projects","title":"Improving your workflow through projects","text":"Experienced programmers learned long ago problems outlined . solve problems, typically use self-contained directory (.e., folder) project. directory contains data code needed create research output project. Notably, code reference data objects found another directory. helps ensure portability - can move entire project still able rerun code. RStudio makes easy create Projects (clarity, use “Project” referring specifically RStudio Projects “project” refer generic research projects, .e., chapter dissertation). highly recommend create new Project project working . several ways easiest way : Open RStudio Click File -> New Project click New Directory (already folder associated project, can click Existing Directory navigate folder) Click New Project choose name location Project (tip - don’t include spaces project name). now worry creating git repository using packrat Click Create Project bottom. RStudio create new directory name Project file called project_name.Rproj inside directory. new RStudio window open create new project. future, want work Project, just double click project_name.Rproj file open new instance RStudio.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/projects_and_directories.html","id":"whats-so-special-about-rstudio-projects","dir":"Articles","previous_headings":"RStudio Projects","what":"What’s so special about RStudio Projects?","title":"Improving your workflow through projects","text":"Projects solve two big problems discussed earlier. First, project opens fresh instance R global environment projects self-contained. means can multiple projects open one behave independently. means rm(list = ls()) objects environment ones associated project (doesn’t totally resolve problem hidden dependencies ’ll talk ). Second, RStudio automatically set working directory root directory associate Project. means whatever folder .Rproj file automatically set working directory open project. can check typing getwd() console new project. setting avoids need use setwd() makes code much portable. can move send entire directory, double-click .Rproj file pick right left .","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/projects_and_directories.html","id":"a-note-on-saving-your-workspace-to--rdata","dir":"Articles","previous_headings":"RStudio Projects","what":"A note on saving your workspace to .RData","title":"Improving your workflow through projects","text":"Another common mistake made many novice (novice) R users save current workspace .RData time quit R RStudio. surface, seems like really convenient shortcut. next time open R, objects created previously right waiting keep going! problem , , creates hidden dependencies. .RData file re-load packages using previous session. re-set options may set previous session (setwd(), stringsAsFactors = FALSE). objects needed , e.g., making figure may loaded others may . means even saved workspace, still end needing re-run chunks code get back left previously. chunks? knows. probably think ’ll remember won’t. better workflow start every R session empty workspace. means go session mindset need re-run code scratch every time. Although seems like pain, promise make life easier. way ensuring minimum, can reproduce analyses anytime need . RStudio, can enforce workflow going RStudio -> Tools -> Global options General tab setting Save workspace .Rdata exit Never. . Trust . re-running code time consuming? really need re-run code cleans raw data every time need reanalyze ? course . can always save objects (along scripts used create !) next time need , can just re-read R can everything downstream steps without problem. One benefits workflow treats raw data code real objects workflow. objects lose , big trouble (’re computer backed , right?). Cleaned data created raw data isn’t real. can just re-run code create objects (use R scripts instead manipulating raw data excel. See details). workspace isn’t real - just discussed, can () disappear time. Results figures real can re-create code whenever need . get mindset treating raw data code real objects, workflow automatically become organized reproducible. (Manuscripts also real save back !)","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/projects_and_directories.html","id":"organizing-your-project-directories","dir":"Articles","previous_headings":"","what":"Organizing your project directories","title":"Improving your workflow through projects","text":"already saw, .Rproj file treats directory working directory project. means can read files location write files location without changing settings. example, can stick filled called data.csv directory following code work: natural instinct us inclined less-organized might put files associated project directory: nothing inherently wrong projects, end big directory hard navigate need find specific files. better idea put files intuitive subdirectories. can pick whatever structure makes sense , generally use something like: data-raw/ contains , guessed , raw data files R script reads raw data , cleans , saves clean data data/ data/ contains cleaned data files ready go straight analysis R/ contains scripts custom functions use data cleaning, analysis, making figures (’ll talk later) figs/ contains figure files doc/ contains files reports manuscripts related projects output/ includes output analysis, example results fitting model scripts/ contains R scripts used analyze data, make figures, whatever. put subdirectory related function script (data_cleaning_script.R) makes sense . can lump different scripts single script prefer. ’s .","code":"data <- read.csv(\"data.csv\") my_proj/ |─── data.csv |─── script_that_does_everything.R |─── test_script_that_does_something_else.R |─── Figure1.png |─── manuscript_v1.doc |─── manuscript_v2.doc . . . |─── manuscript_final_v2-4.doc my_proj/ |─── data-raw/       |─── data.csv       |─── data_cleaning_script.R |─── data/       |─── clean_data.rds |─── R/       |─── function1.R       |─── function2.R |─── figs/       |─── fig1.png       |─── fig2.png |─── doc/       |─── manuscript.Rmd |─── output/       |─── model_results.rds |─── scripts/       |─── analysis.R       |─── figures.R"},{"path":"http://rushinglab.github.io/WILD8370/articles/projects_and_directories.html","id":"readingwriting-from-subdirectories","dir":"Articles","previous_headings":"Organizing your project directories","what":"Reading/writing from subdirectories","title":"Improving your workflow through projects","text":"RStudio treats project root directory working directory, following , example, data stored subdirectory: Instead, need use relative paths. Remember everything relative working directory: prefer, can many layers subdirectories want. important thing long move entire project directory, relative paths still work.","code":"data <- read.csv(\"data.csv\") data <- read.csv(\"data-raw/data.csv\")"},{"path":"http://rushinglab.github.io/WILD8370/articles/projects_and_directories.html","id":"a-suggested-structure-for-this-class","dir":"Articles","previous_headings":"Organizing your project directories","what":"A suggested structure for this class","title":"Improving your workflow through projects","text":"scripts/ contains R scripts created lab. homework/ contains sub-directories files associated homework. exams/ contains RMarkdown files exam (yes, exams completed RMarkdown).","code":"FANR6750/ |─── scripts/       |─── lab1.R       |─── lab2.R |─── homework/       |─── LastnameFirstname-homework1/             |─── LastnameFirstname-homework1.Rmd             |─── LastnameFirstname-homework1.html       |─── LastnameFirstname-homework2/             |─── LastnameFirstname-homework2.Rmd             |─── LastnameFirstname-homework2.html |─── exams/       |─── exam1.Rmd       |─── exam2.Rmd"},{"path":"http://rushinglab.github.io/WILD8370/articles/projects_and_directories.html","id":"a-note-on-handling-raw-data","dir":"Articles","previous_headings":"Organizing your project directories","what":"A note on handling raw data","title":"Improving your workflow through projects","text":"Raw data sacred. purposely accidentally change raw data, everything comes downstream (analysis, results, reports) also change. maintain integrity work, get habit never making changes raw data files entered data. One great things using scripts manipulate data can leave raw data untouched paper trail every change made prepare data analysis. means adding new variables composites raw data (e.g., temp_c <- (temp_f -32)*(5/9)), removing outliers, joining different data sets together, whatever. done R ’ve read raw data rather Excel! Just important, don’t save new data objects raw data even directory. files go data/. means can read data-raw/ write . R , course, allow write data-raw/, just suggestion help maintain firewall keep raw data ’s raw form.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/projects_and_directories.html","id":"additional-resources","dir":"Articles","previous_headings":"","what":"Additional resources","title":"Improving your workflow through projects","text":"RStudio Project webpage Nice R Code Jenny Bryan’s 🔥 take setwd() rm(list=ls()) STAT545’s tutorial workspaces projects","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"logistics","dir":"Articles","previous_headings":"","what":"LOGISTICS","title":"Syllabus","text":"Lecture: Monday, Wednesday 9:10-10:00Location: 1-307 Lab: Wednesday 1:50 – 3:50Location: 1-307","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"instructors","dir":"Articles","previous_headings":"","what":"INSTRUCTORS","title":"Syllabus","text":"Dr. Clark Rushingclark.rushing@uga.eduOffice: Warnell 3-409Office hours: Monday 1:30 - 3:00 Dr. Heather Gayaheather.gaya@uga.eduOffice: Warnell 3-410Office hours: Friday 10:00 - 11:00 appointment","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"course-description","dir":"Articles","previous_headings":"","what":"COURSE DESCRIPTION","title":"Syllabus","text":"Quantitative models play central role linking data inferences ecological processes. Although quantitative ecological modeling involves diverse array questions techniques, many common modeling frameworks based set general underlying principles. course aims provide students firm understanding principles application, particular focus modeling dynamics plant animal populations using Bayesian methods. building common principles specific procedures, students better equipped tailor analyses specific data questions, ultimately leading deeper robust understanding ecological systems study. Concepts discussed lectures reinforced lab exercises focused implementing statistical models using modern software tools (e.g. R, Nimble, git).","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"course-objectives","dir":"Articles","previous_headings":"","what":"COURSE OBJECTIVES","title":"Syllabus","text":"primary objective course give tools tackle research questions using rigorous statistical models appropriate data. particular, leave course : firm understanding foundational principles underlying common ecological models ability express mathematical theoretical models apply common ecological datasets ability convert models working code Bayesian data analysis confidence needed design, analyze, report original ecological research using sound quantitative approaches secondary objective course provide tools best practices storing, manipulating, analyzing ecological data developing reproducible code analyses. experience, graduate students well trained methods data collection , degree, data analysis. However, students receive formal training steps data collection reporting results statistical models (e.g., proofing, storing, formatting data; developing well-documented, reproducible analyses; preparing reports). Advancing field ecology also requires scientific community capable judging quality code, interpretation, reporting quantitative models. Graduate students often get opportunities critically review work peers get constructive feedback reviews. lab portion course specifically designed provide hands experience : Best practices cleaning, formatting, storing data using R Generating reproducible analyses reports using R R Markdown Providing critical peer review scientific code reports","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"learning-outcomes","dir":"Articles","previous_headings":"","what":"LEARNING OUTCOMES","title":"Syllabus","text":"Understand common deterministic stochastic models used analyze ecological data Understand key principles linear models, including design matrices, linear predictors, model interpretations Understand key principles Bayesian statistics, including Bayes theorem, Markov Chain Monte Carlo methods, prior distributions, posterior sampling Understand concepts underlying Bayesian hierarchical models, including fixed vs. random effects, hyperparameters, shrinkage Develop custom Bayesian models using MCMC software (e.g., Nimble) estimate parameter values derived quantities interest common ecological processes able evaluate model convergence/fit Bayesian models able prepare reproducible reports using R R Markdown","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"prerequisites","dir":"Articles","previous_headings":"","what":"PREREQUISITES","title":"Syllabus","text":"Students least one semester basic ecology introductory statistics. Although thoroughly cover foundational principles common statistical models, basic understanding ecological theory statistical inference helpful. lab activities course rely heavily statistical programming language R (associated software, including RStudio, Nimble, git). first weeks, lab session begin tutorial tools students expected experts prior course. However, quickly move activities require degree R proficiency highly recommend basic understanding programming R (e.g., importing/exporting & manipulating data objects, visualizing data) prior course. find struggling aspects using R, please seek individual help office hours. earlier can get speed, painless remainder semester .","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"course-format","dir":"Articles","previous_headings":"","what":"COURSE FORMAT","title":"Syllabus","text":"course taught using lectures labs. Lectures focus conceptual basis ecological modeling Bayesian methods. Labs designed reinforce clarify lecture topics, allowing students get hands-experience manipulating, analyzing, visualizing data. class materials, including lecture slides, computer code, lab documents, data, posted course website prior class.","code":""},{"path":[]},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"textbooks","dir":"Articles","previous_headings":"COURSE RESOURCES","what":"Textbooks","title":"Syllabus","text":"Although many excellent texts covering various aspects ecological modeling, lectures course closely follow two: Hobbs, N.T. M.B. Hooten, 2015. Bayesian Models: Statistical Primer Ecologists (available ) Kéry, M. M. Schaub, 2011. Bayesian population analysis using WinBUGS: hierarchical perspective (available ). Weekly readings assigned books highly recommend students purchase prior start semester. Kéry & Schaub book also contains wealth useful code , although optional, students encouraged implement read text. Chapters books may occasionally supplemented primary journal articles. applicable PDF’s articles posted course website. Although two text books lab materials sufficient mastering material presented course, number excellent books available students may find /books helpful. following books 100% optional course found helpful learning material: Kéry, M. & Royle, J.. 2016. Applied Hierarchical Modeling Ecology: Analysis distribution, abundance, species richness R BUGS. Academic Press. Kéry, M., 2010. Introduction WinBUGS ecologists: Bayesian approach regression, ANOVA, mixed models related analyses. Academic Press. Williams, B.K., Nichols, J.D., Conroy, M.J., 2001. Analysis management animal populations. Academic Press. Bolker, B.M., 2008. Ecological models data R. Princeton University Press.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"lab-materials","dir":"Articles","previous_headings":"COURSE RESOURCES","what":"Lab materials","title":"Syllabus","text":"Materials labs provided HTML R Markdown files course webpage. materials include step--step tutorials lab exercises well links additional online resources, problem sets, homework assignments.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"software","dir":"Articles","previous_headings":"COURSE RESOURCES","what":"Software","title":"Syllabus","text":"lab computers R RStudio installed students required install software computers. However, students free use laptops lab R RStudio installed make easier complete lab assignments outside class. students wishing use computers R, RStudio, Nimble installed running prior first lab. Detailed instructions installing R RStudio can found . plan use computer, sure recent versions three software programs installed. greatly decrease chances running issue running code provide lab. Prior start semester, test R RStudio installed correctly following: Launch RStudio Put cursor window labelled Console. Type following code followed enter return: x <- 2 * 4. Next type x followed enter return. see value 8 print screen. yes, ’ve succeeded installing R RStudio. encounter problems previous steps, please contact instructors prior first class.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"attendance","dir":"Articles","previous_headings":"","what":"ATTENDANCE","title":"Syllabus","text":"graduate students willingly signed course, presume eager learn material self-motivated enough put required effort. reason, set formal attendance policy. However, cover lot material course semester topic build concepts previous weeks. result, missing even lectures labs make difficult fully master learning outcomes described . know missing lectures labs, please contact us advance can make sure get far behind material.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"a-note-on-fieldwork","dir":"Articles","previous_headings":"ATTENDANCE","what":"A note on fieldwork","title":"Syllabus","text":"realize many students field work obligations spring semester. need take course know advance field portion semester, please let us know ASAP can discuss whether field work barrier taking course merely inconvenience. distinction mainly function long miss class. absences relatively , taking course may still option. Students still expected complete turn assignments miss. going miss many classes unable complete assignments ’re field, may better take class time field commitments smaller.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"grading","dir":"Articles","previous_headings":"","what":"GRADING","title":"Syllabus","text":"grade course based total 200 possible points. entire grade come homework assignments. homework assignments build concepts skills cover lecture lab. Specific objectives tasks assignment, along necessary data, posted course website. general, students provided ‘raw’ data need clean/prepare (document!) data prior analysis. assignment due class week assignment posted. assignments must prepared R Markdown files include text, code, model output, figures necessary fully document work conclusions (spend first several labs going preparation reports using R Markdown , , previous experience necessary). See instructions submitting assignment","code":""},{"path":[]},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"university-honor-code-academic-honesty","dir":"Articles","previous_headings":"","what":"UNIVERSITY HONOR CODE & ACADEMIC HONESTY","title":"Syllabus","text":"University Georgia student, agreed abide UGA academic honesty policy. UGA Student Honor code: academically honest academic work tolerate academic dishonesty others Culture Honesty, University’s policy procedures handling cases suspected dishonesty, can found https://honesty.uga.edu/ responsible informing university’s standards performing academic work. Lack knowledge academic honesty policy reasonable explanation violation. Please ask questions related course assignments academic honesty policy. form possible academic dishonesty reported UGA Office Vice President Instruction.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"accommodations-for-disabilities","dir":"Articles","previous_headings":"","what":"ACCOMMODATIONS FOR DISABILITIES","title":"Syllabus","text":"require disability-required accommodation, essential register Disability Resource Center (Clark Howell Hall; https://drc.uga.edu; 706-542-8719 [voice]; 706-542-8778 [TTY]) notify eligibility reasonable accommodations. can plan best coordinate accommodations. Please note accommodations provided retroactively.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"wellness-statement","dir":"Articles","previous_headings":"","what":"WELLNESS STATEMENT","title":"Syllabus","text":"Mental Health Wellness Resources: someone know needs assistance, encouraged contact Student Care Outreach Division Student Affairs 706-542-7774 visit https://sco.uga.edu/. help navigate difficult circumstances may facing connecting appropriate resources services. UGA several resources student seeking mental health services (https://www.uhs.uga.edu/bewelluga/bewelluga) crisis support (https://www.uhs.uga.edu/info/emergencies). need help managing stress anxiety, relationships, etc., please visit BeWellUGA (https://www.uhs.uga.edu/bewelluga/bewelluga) list FREE workshops, classes, mentoring, health coaching led licensed clinicians health educators University Health Center. Additional resources can accessed UGA App.","code":""},{"path":"http://rushinglab.github.io/WILD8370/articles/syllabus.html","id":"ferpa-notice","dir":"Articles","previous_headings":"","what":"FERPA NOTICE","title":"Syllabus","text":"Federal Family Educational Rights Privacy Act (FERPA) grants students certain information privacy rights. comply FERPA, communication refers individual students must secure medium (UGAMail eLC) person. Instructors allowed respond messages refer individual students student progress course non-UGA accounts, phone calls, types electronic media. details, please visit https://apps.reg.uga.edu/FERPA.","code":""},{"path":"http://rushinglab.github.io/WILD8370/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Clark Rushing. Author, maintainer. Heather Gaya. Author.","code":""},{"path":"http://rushinglab.github.io/WILD8370/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Rushing C, Gaya H (2025). WILD8370: Course Materials WILD 8370. R package version 2025.1.0, http://rushinglab.github.io/WILD8370.","code":"@Manual{,   title = {WILD8370: Course Materials for WILD 8370},   author = {Clark Rushing and Heather Gaya},   year = {2025},   note = {R package version 2025.1.0},   url = {http://rushinglab.github.io/WILD8370}, }"},{"path":"http://rushinglab.github.io/WILD8370/index.html","id":"welcome-to-wild8370-bayesian-models-for-conservation-science","dir":"","previous_headings":"","what":"Course Materials for WILD 8370","title":"Course Materials for WILD 8370","text":"unofficial course website Spring 2025 offering WILD8370: Bayesian Models Conservation Science University Georgia. “official” course website (students enrolled course) eLC. goal website create central repository students access course materials - lecture slides, lab activities, code, data, etc. secondary goal make materials freely available students instructors may find useful. encounter issues suggestions, feel free contact clark.rushing [] uga [dot] edu. General course information can found clicking Syllabus Schedule links . Lecture slides lab activities can accessed using drop menus.","code":""},{"path":"http://rushinglab.github.io/WILD8370/index.html","id":"course-r-package","dir":"","previous_headings":"","what":"Course R package","title":"Course Materials for WILD 8370","text":"addition website, materials course distributed R package called WILD8370. main purpose package distribute code data used labs, though eventually additional materials may included, including lectures reference documents. can install current version WILD8370 :","code":"install.packages(\"devtools\") devtools::install_github(\"RushingLab/WILD8370\")"},{"path":"http://rushinglab.github.io/WILD8370/index.html","id":"use-of-material","dir":"","previous_headings":"","what":"Use of material","title":"Course Materials for WILD 8370","text":"Materials included course purposefully made available anyone finds useful. Users free use, adapt, distribute, display, communicate materials freely. find materials useful, please let know, especially using adapting materials teaching. Tracking use materials outside official course great validation effort, helps demonstrate “positive professional reputation teaching.”","code":""}]
